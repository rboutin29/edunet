<div id="fileContents"><h2><strong>Game Theory: </strong>Lecture 8 Transcript</h2><table cellspacing="0" cellpadding="0" id="transcriptHeader" summary="transcript header">	<tbody>		<tr>			<td id="transcriptDate">October 1, 2007</td>			<td id="transcriptNav"><span id="forwardNav"><a href="javascript:history.go(-1);">&lt;&lt; back</a></span></td>		</tr>	</tbody></table></p><p><b>Professor Ben Polak:</b> So last time we left things in the middle of a model, which was the candidate-voter model. What was--I don't want to go over the whole model again, but just to reiterate a little bit--what was different about that model from what we saw before--the main thing that was different was that the candidates cannot choose their positions. If you like, every voter is a potential candidate but you know the positions of the voters. </p><p>Let me just bring out two lessons that we left hanging last time. I want to just put them on the board to make sure they're in your notes. So the first lesson is--one thing we saw already last time--is there can be lots of different Nash Equilibrium this model. There are multiple possible Nash Equilibrium in this model and more to the point, not all of those equilibria have the candidates crowded at the center. We saw early on in the classic Downs or median-voter model that that model predicted crowding the center. This one doesn't, and we'll come back to that in a second. And a second thing we saw last time was that entry can--if you enter on the left one affect of entering on the left can be to make the candidate on the right more likely to win. Conversely, if you enter on the right--you're a right-wing voter candidate and you enter, that can make it more likely that the left wings are--can lead to the winner being more--being further from your ideal position. </p><p>Just to revisit this a little bit, let me go back and just illustrate those two points again. So I'll take a row further back this time and get a nice full row that we can see the whole of. This way, I'm going to take a row further back so that this time we have no confusion about what left wing and right wing is, at least almost no confusion. So let me choose this row, this row good okay. I'm sorry, the people in the balcony are going to have to imagine this. It's a penalty being in the balcony. So this row. And here's my left wing of this row (for everyone who's in front of you which is almost everybody), and here's my right wing. </p><p>Let's try and illustrate some equilibrium we saw last time. So, in particular, if I can get the guy in the blue Yale shirt to stand up a second and the guy with his computer to stand up a second. Sorry. Let's assume all the seats are filled for now so--just to help me out a little bit since I'm doing this on the fly. This, I'm going to claim is an equilibrium. Notice that there are two candidates standing and notice that they are not particularly close to the center. We have our sort of middle-of-the-democratic-party left candidates. So I'm tempted to give you a name but perhaps I will not. And here's a middle-of-the-republican-party candidate. And this is the election. They're going to split the votes equally if I've actually chosen correctly. </p><p>So, just to observe some things here. First, for this to be an equilibrium, it better be the case that they're symmetric on left and right. If they're not symmetric, then it isn't an equilibrium because one of those candidates is going to lose for sure and the way we set up the model that means that one of them will drop out: they will deviate to drop out. Is that correct? Let's also illustrate this. So, we've already illustrated that they're not particularly close to the center. Let's illustrate what I meant by somebody on the left causing the right wing to win. So, if this was the election, here we are getting closer and closer to the election, and suddenly one of our left-wing guys, so Dennis Kucinich or something decides to enter--so let's suppose this is Dennis Kucinich and he enters. If Dennis Kucinich, our left-wing guy enters, there might be some sort of moral victory in entering, but the result of this will be that our right-wing candidate wins; everyone sees that now? </p><p>If these three guys are standing, Dennis Kucinich is going to steal some votes from our center-left candidate and cause our center-right candidate to win. Now, that may or may not be Mr. Kucinich's intention, but we should at least be aware of it. So, this is a real effect. Go back to the 2000 election and think about what happened when Nadar entered and "do the math" as it were, which people didn't do at the time apparently. If you were listening to the newspapers or if you read <i>The New York Times</i> this morning or listened to the radio this morning, you'll find exactly the same debate is going on now in the republican party. Some member--actually it's the other way around, it's the right wing this time; I suppose we should switch it around. </p><p>So the right--some people on the right of the republican party are saying that if it turns out that Giuliani, who currently is leading in the polls, wins the republican nomination they will run a third-party candidate. Of course the debate is actually in these terms. If they run a right-wing third-party candidate--so that would be our guy over here, this might be--this might have payoff in terms of other things. But in terms of the election, it's going to result in Hilary winning. So we've seen these two effects. They're very real effects. We're not necessarily getting people crowding the center and we have to worry about, when we enter, causing the other wing to win. This isn't-- I'm not making a left wing/right wing politics argument here--this is true for both wings symmetrically. </p><p>So, let's try and bring one more idea in here, which is where we ended up last time, which is just how far away from the center can we be? So these guys sit down a second and let's stand up, Mr. Kucinich , again; I know that isn't your real name but never mind. Mr. Kucinich out here on the left and Mr. crazy-right-wing guy whose name I've-- who's the most crazy right wing guy of these candidates? I'm not--I'll get in trouble whoever I name--so whoever the most crazy right-wing candidate you can think of. and now we have the full spectrum represented with just the extremes standing. Here we have--they're symmetric around the center, but I claim this is not an equilibrium. So the people in the balcony, I've got the extreme right and the extreme left standing here. Why is this not an equilibrium? Yeah I should--it's my fault I should have brought the mike. Can I have the mike? I'm sorry my fault. Thanks. This one. So Katie, why is that not an equilibrium?</p><p><b>Student:</b> Because the person in the center could stand up and win the majority.</p><p><b>Professor Ben Polak:</b> Exactly, because the person in the center could stand up and win. Actually, it doesn't only have to be the person exactly in the center. A wide array of center candidates could deviate and win at this point. So, if this was the two candidates standing, and you imagine a third candidate standing, who for example, is this gentleman, if he was to stand, we could--he has to be a little bit closer to the center, let's say this guy, the guy in gray--fairly clearly he's going to end up winning. So this is the third lesson. If the candidates are too far apart we're going to see some center entry, which is going to win. Thank you guys. So even though there isn't this full Downsian effect of pushing candidates towards the center, even though we don't have the median-voter theorem here, we still have part of the intuition surviving. The part of the intuition that's survives is, if the candidates are too far apart, then the center will enter and win. So there is something pulling people to the center still. </p><p>So a reasonable question here is just how far apart in equilibrium can the candidates be? We've established that we can have two candidates and they needn't both be at the center. We've established that they can't be at the extremes. How far apart can they be? Well, this is really just a--it's kind of a nerdy question to get it precisely but let's get it precisely nevertheless. </p><p>So let's have a look, let's use the other board. So, here's the full extent of our political spectrum from 0 to 1, and let me just try and illustrate how far apart these can be. What I'm going to do is I'm going to divide this into sixths - 1/6, 2/6, 1/2, 4/6, 5/6. So I claim--and I'll show afterwards--I'll claim that provided the two candidates aren't outside of 1/6 and 5/6 that that will be an equilibrium. So, in particular, if the candidates are just inside 1/6 and just inside 5/6, or just more than 1/6 and just less than 5/6--so here's one of these candidates who's standing and here's the other one--then we'll be okay. Now why? Why is that the right answer? Anyone want to try a guess? This was the question I sent you over the weekend. I'm sure you were doing other things over the weekend but nevertheless, why is this answer? </p><p>Well, let's see. What are they vulnerable too? They're vulnerable to deviation by somebody entering at the center. And if somebody enters at the center--what would make somebody enter at the center? They're going to enter at the center if they can win basically. So if they enter at the center in this case, let's see how many votes everyone gets. So if we enter at the center here--here's our new candidate--who's thinking about entering at the center. So he's sort of thinking about it. So what's his or her calculation going to be? Well, let's look at what would have happened. So all of these voters are going to vote for our left-wing candidate. So these are going to vote for the left-wing candidate. All of these voters are going to vote for the right-wing candidate. They're all closest to the right-wing candidate. And the middle third--that's a third of the voters, another third--and the middle third (these ones here) are going to vote for the center candidate. Is that right? </p><p>So I've basically divided--the reason I divided it into sixths is I want to put everybody at the middle of a third. So here the left-wing candidate is at the middle of the left third; the right wing candidate is at the middle of the right third, and the center candidate is at the middle of the center third not surprisingly. So if the center candidate enters, if they were exactly at 1/6 and 5/6, they would split the vote and the center candidate would win with probably 1/3. Is that right? But without worrying about that exact case suppose that this--as I claimed that the left-wing candidate is just slightly to the right of 1/6 and the right wing candidate is just slightly to the left of 5/6. Now this left-wing candidate gets a few extra votes here and the right wing candidate gets a few extra votes here (let's put them a bit harder), and you can see now that the center candidate isn't going to win. Is that right? Because the left-wing candidate is getting slightly more than 1/3 of the votes; the right wing candidate's going to get slightly more than 1/3 of the votes; so the center candidate is going to get squeezed out. </p><p>So just a little bit of thinking about it, we can tell in this very simple model the furthest apart the left and right wing candidates can be is at 1/6 and 5/6. They can't go to the extremes, but they're not pulled all the way to the center. So that's just a little bit of nerdy math to confirm it, or nerdy thinking about it. But coming back to our lesson, which is what I guess we care about-- coming back to our lessons, the third lesson here is if the candidates--if the two candidates are too extreme--where too extreme in this model meant beyond&hellip; meant less than 1/6 and more than 5/6--but are too extreme, someone in the center will enter. </p><p>Again, if you look back in both American History and other countries' history, you'll see that when candidates are perceived to be too far apart there's been tremendous temptation for center parties with third parties to establish themselves in the center. So again, with some biased towards England, this is what happened in English History during the Thatcher Period for example. The Thatcher government was perceived to be quite far on the right. The Labor Party at times could be quite far on the left. And we saw a center party set up in between them. </p><p>Okay, so these seem to be the three main politics lessons of this model. Is everyone happy with that? I'm rushing it slightly because we said that already last time and we're happy with how it works? There's a also a Game Theory lesson that I want to just keep in mind here without--well, there's a Game Theory lesson here. And the Game Theory lesson is that our method of finding equilibrium in this model, which was what--it's guess and check--is actually pretty effective. You might think that guess and check, since it doesn't sound like advanced mathematics, wouldn't be such a great way of going about solving games and thinking about them, and thinking about the real world. But actually, guess and check did pretty well here. We were able to make sensible guesses pretty quickly. We were pretty quickly able to figure out what was going on. </p><p>And the key here is what? Without writing it necessarily, the key here is: be systematic when you're guessing. Make sure you've looked everywhere. And second, be systematic, be careful when you're checking. The big error is to ignore certain types of deviation. In this particular model, people very quickly realized that one possible deviation is for someone else to enter. But perhaps they're a little bit less good at spotting that another possible type of deviation is for somebody to drop out. You want to look at all possible types of deviation. But if you're careful, this is a very effective method. So, that's all I want to say about this politics model, and I want to move onto a model that perhaps has more to do with sociology. We'll do a little tour of the Social Sciences here in showing how Game Theory can apply to each in turn. So to do that I'm going to--I'll put this up so you can still read it and work on this board. </p><p>So, we're going to play another game this morning, and it's going to be completely different from the games we've played so far but it's still going to have lessons in it. It's going to be another location model, so that's a connection to what we've done before. But the idea of this game is as follows. We're going to imagine that there are two towns, two possible locations, and we'll call them East Town and West Town. And we're going to assume that there are two types of people in the world. So, there's two types of people, and these types of people are tall and short. Deliberately, this is arbitrary, right? East and West seems kind of meaningless, almost meaningless, in the nomenclature of the towns. I guess there's something about where they are. And tall and short is for pretty meaningless nomenclature for the people, except it says something about how tall they are. </p><p>The idea here is that people are going to choose where they live. Let's assume that there's lots of people. there's 100,000 of each type of person. And let's assume that each town holds 100,000 people. These are fairly big towns. So, the players in this game are going to be the people, the 200,000 people--200,000 tall people and 200,000 short people--but in a minute I'm going to tell you whether you're tall or short. So actually, you're going to be the players in this game. The strategies are going to be a choice of whether you choose East or West. So these are the players and these are going to end up being the strategies. Each of you is going to choose do I want to live in the East Town or do I want to live in West Town? </p><p>So, as usual, what's missing is the payoffs. To model the payoffs, let me first of all draw a picture and then come back and explain it. So, the picture is going to look like this. Here's the payoff picture, and it's a little complicated so just bear with me for a second. So, on the horizontal axis I'm going to put the number of people of your type in the town you end up in. So on the horizontal axis is the number of your type in your town. So the most this could possibly be is 100,000 because that would say everybody is the same type as you in the town and the lowest it could possibly be is 0 because that would say that everyone in the town except for you is of the other type. Is that right? </p><p>I'm going to draw this payoff function. This is going to be your payoff. This is going to be utility--the payoff of you. Let's assume this is Type X, it doesn't really matter. Let's assume this is the tall type payoff which is going to be symmetric for the other type as well. So the payoffs going to look like this. Be careful. Let me draw it and then explain it. That goes like this and then like this. So the idea here--the idea is more important than the picture--the idea is, if you are a minority of 1 in your town, so everyone else is of the other type, you get a payoff of 0. If you are in the majority, and in fact, everyone in your town is of the same type then you get a payoff of a 1/2. And if it's the case that everyone in your town--sorry, if it's the case that your town is exactly mixed, so half of your town is tall and half of your town are short, then you get a payoff of 1. I put a half here. That's really the wrong thing to put here, it should be a 1/2 of 100,000 so I guess it's 50,000. So if it's the case that 50,000 of the people in the town are your type and 50,000 are the other type, then you get the highest possible payoff which is 1. </p><p>So this is--we're going to assume that each and every one of you has this payoff. Does that make sense? So these are people--let's just try and get the idea across in words--these are people who would like to live in mixed towns, but if they're going to live in a town that's not mixed, they'd rather live in a town in which they're the majority. Does that make sense? They'd like to live in mixed towns, but if the town is not--if they had a choice between two towns and the towns are not evenly mixed, then theyd prefer to be in the majority town-- the town in which they're the majority. Everyone understand this? It's important; since we're about to play this game, it's important you're all on board here. </p><p>So to play this game, I need to put down a few more rules. So the first rule is going to be that the choice is simultaneous and that's a little unrealistic because in practice, of course, people choose their towns sequentially, wherever they happen to be moving, but for the moment let's leave it as that. Second, I need to just say what happens if too many people choose the same town. So if there's no room in a town, for example, if too many people chose East Town then we allocate the surplus randomly. We ration the places randomly. So then--we then randomize to ration; people understand that? So, for example, there's 100,000 places in East Town, so if 150,000 people chose East Town, you're going to have a 2/3 chance of getting into East Town and the rest of you is going to be allocated to West Town. Does that make sense? I just need something to make things add up. </p><p>Okay, so to do this, I first of all need to decide who in the class is tall, and who in the class is short (and I'm going to grab that mike again). So let me just count backwards. I guess we'll ignore this row. So, 1, 2, 3, 4, 5, 6, 7, possibly 8. Well, maybe this will work, so up to here this row and forwards you are short people. You understand that? Everyone forward of where I am now, this row included, is short. The rest of you guys and the guys in the balcony too, who can't see me anymore, the guys in the balcony, you are tall. Short. Tall. Okay, so how many rows of these do you have? One, two, three, four, five. Seven rows here, all right. One, two, three, four, five, six. We have seven rows of short people and the rest of you are tall and I'm going to hope I've split that evenly. I'm going to cheat a little bit--in a minute, you're going to have to choose which town you're going to live in and we'll do it by show of hands. </p><p>But before we do that I'm going to cheat a little bit by giving each of you an initial position --;this is irrelevant but I just want to sort of set things up. So what we'll do is we'll put this row--so this row, one, two, three, four--these rows, your initial position is in East Town. It doesn't matter, you can move, but your initial position is in East Town. So East, East, East, East--everyone understand that? These three rows, this row, this row, and this row, you're in West Town. And these next four rows--so you guys, you guys, you guys, and you guys--let's do it again, this row, this row, this row and this row you're at East Town and--oh, I didn't notice this row--you're in East Town as well, up to here is East Town. And the rest of you is in West Town. Okay, everyone understand where they are now? Let's do a test with the camera watching. So if you are currently in East Town raise your hands. And if you're currently in West Town raise your hands. So I've set you up with a stripy pattern and notice that I've set things up so that slightly more of the short people were in East Town and slightly more of the tall people--if I did that right--were in West Town. If I did that correctly--I'm not sure I did actually--but if I did that correctly, slightly more of my short people started life in East Town, and slightly more of my tall people started life in West Town. </p><p>Okay, so now think about it a second. Remember, these are your payoffs. That's a suspension of disbelief. These are your payoffs. And in a minute I want all the people who are choosing East Town to raise their hands. I'm going to do it at a count of three and don't cheat. Don't look around you and see what's going on. You all close your eyes. Everyone in the room close their eyes. I can do anything now; I could be stripping naked. So, you've all got your eyes closed. On the count of three, anyone who's choosing East Town should raise their hands 1, 2, 3--so this is my East Town. People can open their eyes now and look at the East Town distribution. So I've got this big block of East Town here. I've got a little bit going on in the wings, a little bit of spillage here. Let's just make--let's just check it so those of you who didn't raise your hands just now are West Town. </p><p>So, West Town people raise their hands, so we've got a little bit of spillage here but basically I've got West Town over here. Everyone understood just what happened? Everyone saw what happened? Let's do it again. That's where you are now; let's see what happens next time. So once again close your eyes, don't communicate. Everybody who's going to choose East Town raise their hands now. So I've got pretty much all of these rows now are in East Town and a little bit of spillage here, but basically I've got East Town in the front; I can't see the balcony. What do I got in the balcony up there? No hands up in the balcony; that's typical. They live in the balcony, right? So I've more or less got East Town here. Where's my West Town? Raise your hands if you're in West Town now. West Town: a little bit of spillage here but basically I've got West Town in the back. </p><p>Let's do it one more time, everyone understands where things were just now? Am I leaving the hands up long enough? Are they up long enough? Okay, so let's try it again. So East Town on the count of three 1, 2, 3. So here's my East Town. I'm pretty much in the--among the East Town dwellers right now. West Town raise your hands 1, 2, 3. And I'm pretty much in the West Town dwellers right now and it's not at all stripy. We started up with a stripy pattern and we ended up--we ended up how? We ended up with pretty much the whole front of the room choosing East Town, and the whole back of the room, maybe including the balcony, choosing West Town. The balcony were just flowing over. So everyone saw what happens. </p><p>Now, can anyone say what's happened there? Why did we end up like that? How did we end up like that? We started off with a stripy pattern. It was a little bit off from being kind of perfect, because all of you, by these preferences would prefer to be in a town that was exactly 50/50. It wasn't quite at 50/50 but it wasn't far off actually and we pretty quickly ended up with all these short people, you guys are short all living in East Town and all of you all tall people living in West Town. So all of you pretty much ended up with a payoff of 1/2. Some of you didn't, there are a few deviants. Who are my deviants? Who are my guys--who are my tall guys who end up East Town? So these guys. It's fine, but they end up with a payoff close to 0. And who are my short deviants who ended up in West Town? There's a few. Not many of them at all actually, but a few of them, but they end up with a payoff of 0 as well. But pretty much everyone else was ending up with a payoff close to a 1/2, and splitting down the middle of the room. Now, why? What do we call that? What do we call that process? What's the outcome here? </p><p><b>Student:</b> Segregation.</p><p><b>Professor Ben Polak:</b> Yeah, so this--say that again.</p><p><b>Student:</b> Segregation</p><p><b>Professor Ben Polak:</b> So this is segregation. Right, we ended up getting the class to segregate on tall and short. It wasn't that people wanted to segregate. I gave you the preferences. I told you that you have to have these preferences, which may have actually been the preferences that favored being in a mixed town, but we very quickly settled down to a segregated distribution of the class. Why? What led to that? Let's just talk it through a bit. Who has an opinion of what it was that kind of got us there. Yes, so Patrick shout out for the classroom. This doesn't speak to the class.</p><p><b>Student:</b> I mean, I think what happened is basically because it was the first choice is simultaneous. Everyone in the slightly bad situation all changed to what was perceived to be a better situation. So we sort of shot past the equilibrium where we were 50/50.</p><p><b>Professor Ben Polak:</b> Right, so we--I cheated a little bit by starting you off away from the 50/50 point and you kind of went further very, very quickly. Now, I want to say that I think with a longer time period to play with I could have started you off just random, just choose whatever, and if we played enough times my guess is we would have ended up segregated anyway. It might not have been segregated with East here and West there, might have been the other way around, but I'm pretty sure we'd have ended up segregated anyway. I can't prove that because I can't--we wouldn't have enough time to do it. I cheated by pushing us that way. </p><p>So what happened was--is this right? People who started off in the minority but not badly in the minority in--who were short guys in West Town--they moved to East Town. That was largely the rows here; you guys moved to West Town. And guys who ended up--who I started off in the minority--I'm not even sure it was actually a minority--who were tall guys in East Town you guys drifted over to West Town. Is that right? Okay, we'll talk about this more in a second, but let's just get some ideas down on the board. Well, no--I don't know. Actually, while I'm down here let's do a little bit more work. </p><p>So before we leave this, I mean before we leave talking about it, let's figure out what are the equilibria here. So what's an equilibrium of this game? It's a pretty simple game. It has lots of people, two choices per person. We're going to be doing guess and check here. So what do people think the equilibrium is? Let me get someone who hasn't spoken yet. I surely shouldn't have to cold call here. This is an easy one. What's an equilibrium here? Somebody? What's an equilibrium here? How about the gentleman here. You want to have a guess at what the equilibrium is?</p><p><b>Student:</b> Everyone being segregated.</p><p><b>Professor Ben Polak:</b> Everyone being segregated. Let's be a bit more precise. So I claim there's two ways they can be segregated. So spell out the two ways.</p><p><b>Student:</b> If all of the tall people are in West Town and all the short people are in East Town, or if all the tall people are in the West Town and the other way around.</p><p><b>Professor Ben Polak:</b> Good and your name is?</p><p><b>Student:</b> Greg.</p><p><b>Professor Ben Polak:</b> So Greg is saying there's two ways to be segregated and each of them seems like an equilibrium. Let's just spell it out. So all the tall people being in the East is one equilibrium, and all the tall people being in the West is the other equilibrium. Both of those, I claim--or Greg claims a bit more carefully--Greg claims both of those are Nash Equilibrium. How do we check that they're Nash Equilibrium? I mean they are, you're right, but how do we check that they are in fact equilibrium? How do we go about checking that they're equilibrium? The guessing part is easy, checking requires a bit of thought, so how do we check? Yeah.</p><p><b>Student:</b> You check for profitable deviation.</p><p><b>Professor Ben Polak:</b> You check for profitable deviations. So what's a deviation here? If all the short people are at East Town and all the tall people are at West Town, what's a deviation? A deviation--let's ignore the capacity constraints for a minute--a deviation is for one of the short guys to move to West Town. Is that right? So at the equilibrium that short guy was getting a payoff of what? What was his or her payoff in equilibrium? One half. If he or she deviates and moves to West Town, again ignoring the capacity constraints, let's assume that they can, if that short person moves to West Town what's their payoff going to be? Zero. So that's not a profitable deviation. Conversely, if we did the same from the other side for the tall people, we'd find the same thing. So we've just checked that that is an equilibrium because nobody can deviate profitably. So we found two equilibria here and as people pointed out they are segregated. Now, I claim that there's another equilibrium here. What's the other equilibrium here? I should get the mike right there on the other side. So let me try and lean in here, lean my way. Yeah can you--thanks.</p><p><b>Student:</b> If you were to put exactly 50/50 then that would be an equilibrium. </p><p><b>Professor Ben Polak:</b> Good, so if the crowd had split 50/50 that would also be an equilibrium. Right, but the key word there is what? The key--50/50 is the key word. What's the other key word there? Exact; it really has to be exact for this to work. And since I'm hand waving a bit because equilibrium are always exact statements, but can people see what's going on here? So if people split exactly 50/50, right split the class down the middle--I start off by splitting it this way into tall people and short people--if I had split the town down the middle into East and West, then everyone would have been happy and they would have stayed put. That's this gentleman's claim and I think that's correct. But what's suspicious if you like, what's worrying about that equilibrium? That is an equilibrium. What's worrying about that equilibrium, that mixed equilibrium, that integrated equilibrium? Can we get the guy here? </p><p><b>Student:</b> It's a weak Nash Equilibrium because while there's no real incentive for you to deviate, there's no incentive for you to not deviate either.</p><p><b>Professor Ben Polak:</b> Good, so one thing that distinguishes--thank you that's very good. So one thing that distinguishes that equilibrium from the equilibria that we were just looking at is it--sometimes it's weak, whereas, the other ones are strict. What do we mean by that? If we deviate away from this exactly mixed equilibrium, roughly speaking, a little bit of hand waving here, but roughly speaking we're exactly indifferent. It's true, that's not strictly true because I guess by ourselves moving we're changing the balance a little bit, but nevertheless we know if I smooth out the top it'll we'll be exactly right. </p><p>So at that mixed equilibrium--I don't want to call it a mixed equilibrium--at that integrated equilibrium, I'm exactly indifferent about where I live, both towns look the same to me. They're called East and West but they have the same mixture of tall and short people in them. Whereas, at the segregated equilibria, I strictly prefer to go to the town in which I'm the majority. I'm doing a strictly higher payoff, 1/2 versus 0, by being in the town in which I'm in the majority. So there's this notion of strictness, there's also a notion of stability here, so again, I don't want to be too formal here. I want to give you an informal idea about why we might worry about stability. So what do I mean by stability here? Why do I think that that integrated equilibrium in which we divide the towns equally might not be stable? What do we mean by that? For the physicists this is an easy idea, but for everyone I think it's a fairly intuitive idea. Why is that not likely to be stable? Anybody? Yeah here. What's your name?</p><p><b>Student:</b> Chris.</p><p><b>Professor Ben Polak:</b> So why?</p><p><b>Student:</b> If even one person deviates and all of a sudden then everyone would prefer to deviate to the completely segregated position.</p><p><b>Professor Ben Polak:</b> Right, good. So at that integrated equilibria, if we move away from it a little bit, if it turns out that, let's say, one town has 5% more short people and the other town has 5% more tall people, then in some sense we're in trouble already. We haven't gone very far from this nice equilibrium but already we're in trouble because now all of the short people are going to prefer East Town and all of the tall people are going to prefer West Town. And in a few moves we're very quickly going to be back at segregation again. It's not stable in the sense that if we were a little bit off we're going to go a long way off. Again, I'm not being formal here but the informal idea I think is important. </p><p>Conversely, those segregated equilibria, because they were strict equilibria, as the gentleman over there was pointing out, they're already pretty stable. If we start close to 100% short people in East and close to 100% tall people in West and then we move it a little bit away, so I shake you up a bit and I force you to--I reallocate a few people and then let you play, I claim you'll go back to that equilibrium. Is that right? So, the equilibrium that is integrated here, it is an equilibrium, it's only a weak equilibrium and it's not very stable in some sense. Whereas, the segregated equilibria, they're clearly strict equilibria and they are stable. </p><p>Let's put some of this down on the board now, partly because it feels weird for me being out there, even if it doesn't for you. So, we've got this several equilibria here; we've got at least three and we'll come back and talk about whether there are others in a minute. We've got at least three equilibria, two of them are segregated. So the Nash Equilibrium in this game--we have two segregated Nash Equilibria and these correspond to tall in East and short in West and vice versa. We had a separate one which was an integrated one which was roughly half of each in each town. So there's at least three equilibria here, although the two segregated ones are kind of the same, and we argued that these segregated equilibria were in some sense stable and they were strict equilibria in the sense that you strictly preferred not to deviate. Whereas, these integrated equilibria, these were actually perhaps not stable, and again I'm not being formal here, so I was being a bit careful putting it in inverted commas, and again, a little bit informal but a kind of weak equilibrium. </p>
<p>Now, I want to bring up one other concept here, which is the idea of a "tipping point." So this is a game that was introduced by a guy called Schelling. Schelling went on to win the Nobel Prize largely for this; certainly in large part for this idea. This is a game that has a tipping point. There are really two stable equilibria, the segregation of one way and the segregation the other way, and in between there's a tipping point beyond which if you--beyond which--if you go beyond which you go to the other equilibrium. I said that very badly, but do people get the idea? There are two strict equilibria and if we got beyond the points of a 50/50 mix going the other way, we can whiz off to the other equilibrium. </p><p>We already saw a game that had a tipping point when we played the investment game, where there were two equilibria, all invest and no one invest, there was a natural tipping point in that game and the tipping point was having exactly 90% of you invest, the point at which you actually would want to flip over and go to the other equilibrium. So this is a game that has a tipping point. We can push people away from the equilibrium and they'll go on coming back and they'll go on coming back and go on coming back, but if we just push them a little bit beyond a half, whoops, they'll go on off to the other equilibrium; very dramatic change. That seems like a rather important idea in, for example, sociology. </p><p>So I've got these segregated equilibria and I've got these integrated equilibria and let's just make the other obvious remark. Which of these equilibrium is preferred by the population? Would they rather be in the integrated equilibrium, given that these are their payoffs, or the segregated equilibrium? They'd rather be in the integrated one. So here's a world in which they'd like to be in the--everybody would like to be in the integrated equilibrium. This is not a Prisoner's Dilemma. This is not a case that we've seen before but it turns out that you're likely to end up in these inefficient, less preferred by everybody, segregated equilibria. However, if we're subtle about this, you might notice there's actually a third equilibrium in this game. If we're a little bit nerdy, there's actually another equilibrium in this game. So, I'll need to give you your mike back, I'm sorry. There's a guy there in gray.</p><p><b>Student:</b> If everyone chooses one town or the other, regardless of whether they're tall or short, then they would be redistributed.</p><p><b>Professor Ben Polak:</b> Good, your name is?</p><p><b>Student:</b> Nick.</p><p><b>Professor Ben Polak:</b> Nick; so Nick's pointing out there's actually hidden in here another equilibrium. It doesn't sound like anything very realistic, but let's just focus on it a second because I think it's an important lesson here. There's going to turn out to be important lessons. The other equilibrium is--actually there's two of them--is if everybody, everyone in the room chose East Town, what would happen? Well, we'd have to find a way of assigning everybody, so what we would do is we'd essentially randomize over the room and half the room would be in East Town and half the room would be in West Town. So there's this kind of silly equilibrium in a sense, in which everyone does the same thing, and the way in which people actually get allocated is not by their choice but by this detail of the original game, which was if there was overcrowding we were going to randomize people. </p><p>So, there is actually a third equilibrium which is all--there's two of these of course--so all choose the same town and get randomized. To check that is an equilibrium, notice that if everyone else is choosing--if everyone else is playing this strategy of all choosing East Town and allowing the randomization device to place you, then you're completely happy to do that, completely happy to do the same thing. So it is in fact an equilibrium. So, this is a slightly odd equilibrium here, and there's immediately a Game Theory lesson here. </p><p>This equilibrium, sounds like something we might see in society, and this one's certainly worth talking about, it seems a natural part of the game. This equilibrium seems to have nothing to do with anything that's really in the world. It's just arising from a particular detail I threw into the model at the end to make things add up. Is that right? When I was setting up this model and describing reality, I threw this in at the end to say we better do something just to make things add up, otherwise towns are going to be overcrowded. It wasn't that's really out there in the real world. It was just to make it a game, sort of define things carefully. This seemingly innocent detail of my modeling technique threw up another equilibrium. So there's a sort of warning lesson here. The lesson is, seemingly irrelevant details of the game, things that aren't really attempts to capture reality, they're just trying to get things through in a hurry, can end up mattering--can matter. They can lead your game to give you a prediction you really don't believe in. Is that right? Well, that's a very general lesson for those of you who are going to go out and model things more widely. </p><p>There's a second lesson here, however. The second lesson here is if in fact, if this randomization process was available, if in fact it was possible for everyone in the town to chose East Town and then have the local government randomize you, then if we use the law of large numbers, if there's 100,000--I guess 200,000 people in all and they're all being randomized, we're going to end up very, very close in the limit exactly at integration and everyone's going to be better off. Is that right? So the other kind of strange thing here is by randomizing--wll, I don't want to say randomizing, I want to say having society randomize for you--ended up being better than choosing--ended up better than, what you might want to call "active choice." Here's an example of a place where by abdicating the right to choose my town and simply by all choosing East, having society randomize for me, we ended up better off: a slightly surprising result. </p><p>Let's try and push this a little harder. Okay, so let's try and draw some lessons. We've drawn out some Game Theory lessons already from this about irrelevant details and about stability and so on. Let's try and draw out some other lessons here. So, one lesson might be a lesson in sociology. I'm not a sociologist so I want to be careful. I'll put it in inverted commas. The sociological lesson is what? In this game, segregation is what resulted, at least in the stable equilibria, and you might be tempted if you're an empirical sociologist, to go around the world and say, look I see segregation everywhere. I've gone from country to country, from society to society, and wherever I go I see segregation. You might be tempted to conclude that that's because people prefer segregation and that might be right. Nothing in this model disproves that. It might be the facts that--it might in fact be in the case that the reason you see segregation in virtually every society is because segregation is preferred. I'm not ruling that out here I'm just raising another possibility. </p><p>What's the other possibility? The other possibility is it could be that preferences are like this, roughly speaking. People don't actually prefer segregation, but when all people act in their own interest you end up with segregation anyway. So, the fact that that we're seeing segregation in this model does not imply that there's a preference for segregation. It doesn't rule it out, of course, but you can't conclude, just because you see segregation everywhere that necessarily people want segregation. Let me just take that outside of the context of segregation, more generally. If you see a social phenomenon in society after society, after society whether they are anthropologists going across societies or a historian going through societies in historical time, and you see the same phenomenon in each of these societies which results from the choices of thousands of different people, you can't conclude from the fact that you see it in all of these societies that those people prefer it. </p><p>All you know is that each of their individual choices add up to this social outcome that may or may not be something they prefer. In this case it's not. That was really Schelling's big idea. I don't want to write that all out but it's kind of a--it's a huge idea. It got him the Nobel Prize. So you don't want to conclude from observation straight back to preference in these strategic settings. </p><p>Now, this matters a little bit, obviously in our own society because we live in a rather segregated society. I mean, we needn't be quite so coy as to talk about tall people and short people all the time, what we're really talking about mostly I guess in our society is ethnic segregation, and we see this very dramatically in Connecticut, for example. So where we live in New&nbsp;Haven, at least if you go a few feet outside of the university, and actually where people live in New&nbsp;Haven, we see that New Haven is a fairly integrated town. It's not a hundred-percent integrated town but it has a fairly wide array of ethnicities. </p><p>But if you go upstate in Connecticut, if you go north, ignoring Hartford, if you go in the rural areas of Connecticut, you find something dramatically different. How many of you have traveled around in rural Connecticut? Some of you have. So it's quite shocking for me as a foreigner when I came here. So New Haven and the towns along the coast are fairly integrated but, if you drive into rural Connecticut, you see something quite different. So this weekend, for example, I was up at the Durham Fair. How many of you know what the Durham Fair is? Some of you know. The Durham Fair is actually very good. It's a place where you can--it's the biggest agricultural fair in Connecticut and you can take your kids there, I have a four-year old and a two-year old, and they discover at this fair that in fact it is the case that cows say moo and sheep say baa. Who knew? Right, that's a good thing. So I don't want to knock the Durham Fair. I think it's a good thing. </p><p>But if you're wandering around the Durham Fair and you're a social scientist as I am I guess, you can't help but be struck by--how do I put this without getting in trouble? You would find more ethnic diversity at a Klan rally. This is not--I mean this is--that's not going to get me out of trouble. There's got to be some way of saying that it doesn't get me in trouble. Okay, but you know what I mean, right? It is strikingly, strikingly white at the Durham Fair. We're only--what--it's about--I think it's 18 miles from New Haven. It's a 20 minute drive from here. It's a public event, 20 miles from New Haven. So this is a phenomenon one might be tempted to say, this is because people choose, people want-- clearly, people are choosing to go to the Durham Fair; they're choosing to some extent where they live in Connecticut. And you might think the fact that we see this incredibly dramatic segregation between activities in New Haven and activities 20 miles away is evidence that people might actually prefer segregation. And just to repeat, I can't prove that it isn't. But we have to be at least aware of the possibility that it's got nothing to do with the preference for segregation; it could be the preferences look like the preferences above. </p><p>It could be that simply thousands of activities by thousands of individuals, who at least would prefer to be in the majority than the--they'd rather be in the majority and not the minority, but they'd like to be integrated--leads to incredible segregation in the aggregate. </p><p>So let's talk about policy now. So as I go down here I'm getting more and more in trouble I'm sure as a foreigner. This is a big policy question in the U.S. How many of you are unaware of the fact this is a big policy question in the U.S.? So at least since the 1960s this issue about segregation versus integration has been a hot-button issue, particularly in what part of social life? </p><p><b>Student:</b> Schools bussing for segregating schools.</p><p><b>Professor Ben Polak:</b> Schooling okay, your name sorry?</p><p><b>Student:</b> Jessica.</p><p><b>Professor Ben Polak:</b> So Jessica's pointing out correctly that since the 1960s, this has been an incredibly hot issue in the U.S., and we're talking about the bussing debate. How many of you have not heard of bussing? How many of you have heard of bussing? So it's slightly a policy debate of the 1960s so people tend to forget it, but in the 1960s and early 70s, people were so worried about segregation in schools that they--that children were bussed from one neighborhood to another neighborhood to go to school. This was an incredibly controversial issue in the U.S.. And I'm not--I don't want to take a position on it here. I just want to point out that you could arrive at that policy by thinking about this kind of model. </p><p>In fact, this is not just an issue of history. If you read the newspapers last week, including the <i>Yale Daily</i>, you'll see that it's an issue today in Connecticut. There's a worry in Connecticut today, particularly around Hartford, that the schools are still illegally segregated. They're not in compliance with the law. So this continues to be an issue. Let me take to a slightly less contentious area, since that's obviously so contentious, and talk about--and try and relate it back to the model a bit. So in the model what we saw was if everyone chose to go to East Town or if everyone chose to go to West Town, there was a policy that was a little bit like bussing going on. If everyone chose to go East Town, what we ended up with was randomized placement across the towns. Is that right? That's a little bit like the bussing policy. It says everybody--we take away people who we--take away people's active choice of their school and in place we just randomize everybody. </p>
<p>So leaving aside what happened in Connecticut, let's think about a school, not a very good school, but a school that's a little bit north of here. So there's this school called Harvard and so that's--Harvard is outside Boston and at least when I was there as a graduate student, this was a hot issue in Harvard. So whereas Yale has colleges, Harvard has "houses," but they're the same thing. They are the same thing; it's just the same name for they're--maybe they're not the same, maybe there's some subtle difference--but they're roughly speaking the same thing. I'm still getting hissed. So these houses at Harvard, at least until about 1990 I think, roughly, certainly when I was there as a graduate student, the way in which you ended up at a particular house was that you chose which house to be in. </p><p>Harvard administrators started worrying. So these houses started looking--started taking on certain characteristics. So, for example, there was a house--I guess there still is--called Elliot House, and if you went to, as I used to occasionally as a graduate student, go and eat a dinner at Elliot House, you'd meet all these people. And it was kind of an odd experience because more than half of them had names that just happened to be the same as the swimming pool that had just been built at Harvard. Then if you went to Adams House, where I was actually a tutor, it was a very different mix of people. And an extraordinary large portion of them were daughters of recently deposed Latin American dictators. It's not exactly what you expect to meet at random. And then to give you a third example, there was a house called--it's wrong now, Kirkland House, is that right? Kirkland House. And Kirkland House was known to be the jock house, the athlete house, and of course this being Harvard that meant that everyone there was Canadian. So this was--this worried the Harvard administrators. So they were worried about it and presumably they were worried that little Ms. Pinochet wasn't going to have a chance to meet Mr. Master Gretzky or something, whatever it was. So they did something about it, so what did they do? What did the Harvard administrator so to change this outcome? Anyone know? Shout it out.</p><p><b>Student:</b> They randomized it. So you go in as a group but you don't get to choose which one you're going to go into.</p><p><b>Professor Ben Polak:</b> Right, so what happened was they imposed randomization. They did exactly the policy that we described up here. This was essentially their policy and notice actually the policy that they adopted, the policy in which house allocation was random, was basically going to what the policy Yale had all along. So as happens in other cases in education, Harvard arrived at the Yale solution eventually. So randomization or more dramatic things like bussing are policies arrived at really because we know of the existence of these models. I'm not saying these are right or wrong.; It's not my position to say that they're right and wrong. I'm saying if you were going to argue for these policies, this might be a way in which you might argue for these policies. </p><p>Now, I want to bring out the third lesson here, and the third lesson here is once--we've drawn--I've already said I won't repeat it, there's a Game Theory lesson here about irrelevant details; irrelevant details mattering, but I want to bring out one more Game Theory lesson here. So here we've been discussing randomization in these settings in the following form. In the game, the local governments randomized where you lived. In the bussing experiment it was randomly chosen who went to which school. I guess it was done by social security number, I don't know. In Harvard and in Yale too, there's some randomization about which college house you live in. That's one way to achieve randomization: you could have it done centrally. The central administration, this local government, the central government, can randomly assign people. But in principle, there's another way to achieve randomization. What's the other way you could achieve randomization? Both in this experiment and elsewhere. There was a hand way in the back; can we get it?</p><p><b>Student:</b> Each player in the game could randomly choose.</p><p><b>Professor Ben Polak:</b> Right, so rather than having centralized randomization, in principle, you could get to the same outcome by having individual randomization. So there's another possibility here, which is individual randomization. In principle, you could have everybody in the room decide that what they're going to do is throw a coin, a fair coin, each of them separately, and if it comes up heads they'll go to East Town and if it comes up tails they'll go to West Town, and if all of them do that and they all stick with it, again, by the law of large numbers we'll get pretty close to integrated towns. But it won't have been some central authority doing the randomization. it'll be each of you individually doing the randomization. Is that right? </p><p>So that's a little bit different, and notice that if everyone else is doing this, if everyone else is randomizing, the towns will in fact be, at least asymptotically, the towns will be equally mixed and you'll be happy to randomize. Why? Because you'll be indifferent whether you end up in East Town or West Town, so you may as well toss a coin anyway. So this is actually another Nash Equilibirum. I'm being a bit loose here but we'll be much more precise in a moment. There's another Nash Equilibrium, yet another Nash Equilibrium, in this model, and it isn't as silly in some sense as having everyone going to East Town and then having the government randomize. It's each person on their own tossing a coin and deciding where to go. It sounds a little bit less like central planning and more like choice. </p>
<p>Now, however, as soon as we introduced the idea of individual randomization we've gone a little bit beyond where we got to in the class. Why? Because so far in the class, we've talked about strategies as the choices that are available to you. The choices available to you were go to the East Town, go to the West Town. Or, in the numbers game we played, it was choose a number. Or, in the &#940; &#946; game we played, it was choose &#940; or &#946;. Or deciding whether to invest or not, it was invest or don't invest, and so on and so forth. What we're seeing now is a new type of strategy. And the new type of strategy is to randomize over your existing strategies. So we're introducing here a new notion that's going to occupy us for the rest of the week, and the new notion is a randomized, or as we're going to call them, "mixed strategies." </p><p>So what is--I'll be more formal next time, but what is a mixed strategy? It is a randomization over your pure strategies. The strategies that we've dealt with in the course up to now, from now on, we're going to refer to those as pure strategies, they are your choices. And we're going to expand your actual available choices to include all randomizations over those. This may seem a little weird, so to make it seem a little bit less weird, let's move immediately to an example. So, the example I want to talk about is a game that I think is familiar to a number of you, but I'll put up the payoffs and see. So the payoffs look like this; each person has--there's two players--each of them has three strategies and the payoff matrix looks as follows: (0,0) is down the lead diagonal and going around it's going to be (1,-1), (-1,1), (-1,1), (1,-1), (1,-1), (-1,1). </p>
<p>Now, without me putting anymore letters up there what is this game? Right, so somebody shouted it out, this is "rock, paper, scissors." So I think, if I get this right, this better be rock, and this better be scissors actually and this better be paper. This is rock, paper, scissors. How many of you have not heard of rock, paper, scissors? Good; the other day I was flicking channels and ESPN had a rock, paper, scissors contest and I just want to know who watches that? So this is quite a fun game and it occurs all over the place. It occurs even in episodes of the Simpsons. So there's I guess by now famous episode of the Simpsons in which the kids who are I guess Bart and Lisa, is that right? Somebody help me out here, Bart and Lisa is that what they're called? So Bart and Lisa are playing rock, paper, scissors for some purpose, to allocate some prize. And Bart is seen to think (as you can do it in cartoons) seed to think, "Rock, paper, scissors, I love playing rock, paper, scissors. Rock rocks. What could possibly beat rock?" Lisa is seen to think, "I love playing rock, paper, scissors; Bart always chooses rock." </p>
<p>That's really a hint of where we're going here. That's a hint of where we're going. This is a very simple game "rock, paper, scissors," but it's pretty obvious, I hope, that pure strategies in this game are probably not enough to model this guy. Is that right? So, in particular, I claim and if necessary will prove that there is no Nash Equilibrium in pure strategies, in the strategies that we've been looking at up to now. There's no Nash Equilibrium in which people choose pure strategies here. So there's no Nash Equilibrium. From now on I'm going to use the term pure strategies to mean the strategies we've been looking at so far. So by pure strategies here, the set of pure strategies is equal to the set rock, paper, and scissors; so what we've called strategies up to now in the class. </p><p>So now, can everyone see why there's not going to be a Nash Equilibrium in pure strategies? Let's just talk it through. So, if one person plays rock, the best response against rock is? Let's try that again; you all know. Best response to rock is? Paper; but if you played paper the best response to paper is? Scissors; and the best response to scissors is? Rock; so everyone knows how to play this game. So clearly, there's not going to be a pure strategies Nash Equilibrium, right? Because any attempt to look for best responses that are best responses to each other can lead to a cycle. Everyone see that? There's no hope of finding two pure strategies that are best responses to each other because of that cycle. </p><p>It's also, I claim, pretty easy to figure out what must be the Nash Equilibrium in this game. We're going to prove it in a second, more or less, but nevertheless I think we actually know it. So what is, in fact, the Nash Equilibrium strategy in this game? Let's get some--you could probably cold call somebody; just cold call somebody at random. I'm sure they all know it, so just cold call somebody. So what's the--yeah the gentleman in yellow--what's the Nash Equilibrium in this game? I'm allowing you mixed strategies now; I'm allowing you to randomize--if I allow you to randomize over your pure strategies, I'm allowing you to play mixed strategies, what's the mixed strategy we think people are going to play? </p><p><b>Student:</b> No idea.</p><p><b>Professor Ben Polak:</b> No idea; you should be on that--I want to play against you. Let's have someone else picked out, yeah. What do we think is likely to be the mixed strategy people are going to play in this game in equilibrium?</p><p><b>Student:</b> No idea.</p><p><b>Professor Ben Polak:</b> No idea? Who here is regarded as a champion of "rock, paper, scissors" player? </p><p><b>Student:</b> Playing each choice with one-third probability.</p><p><b>Professor Ben Polak:</b> Thank you. I thought that would be okay. So I'm--people didn't play this with their siblings? Maybe they did and they just lost a lot. So I claim as a guess that the Nash Equilibrium is each player, both players, each player chooses--and I'm going to call it 1/3, 1/3, 1/3--in other words, each player is playing the mixed strategy 1/3, 1/3, 1/3 which I'm sorry I didn't catch your name, your name is?</p><p><b>Student:</b> Moses.</p><p><b>Professor Ben Polak:</b> Which is Moses' recommended strategy. So each player is going to play 1/3, 1/3, 1/3. So I'm actually amazed that people didn't realize that and again I'm sort of puzzled as what happened in your childhood, but never mind. Let's figure out what in fact is the payoff to each of the pure strategies against it. So what I'm going to do is I'm going to show you that this will in fact be a Nash Equilibrium by showing you payoffs. So what's the expected payoff--to start off, what's the expected payoff of rock against 1/3, 1/3, 1/3? So the other person's randomizing equally over rock, paper, scissors and I'm going to choose rock. What will be my payoff, my expected payoff? Well, I claim that with probability 1/3 I'll meet another rock and get 0, and with probability of 1/3 I'll meet a scissors and get -1 and with probability of 1/3 I'll meet paper--I said that wrong, let me start again. The probability 1/3 I'll meet rock and get 0, probability 1/3 I'll meet scissors and get +1, and a probability 1/3 I'll meet paper and get -1. Is that right this time? </p><p>So my expected payoff is what? It's 1/3 of 0, 1/3 of +1, and 1/3 of -1 for a total of 0. It's not hard to check that the same is true if I chose scissors. If I chose scissors and the other person is randomizing 1/3, 1/3, 1/3 then with probability 1/3 I will get -1, with probability 1/3 I will meet another scissors and get 0, and with probability 1/3 I'll meet paper and get 1, and once again it nets out at 0. Finally, if I played paper, and once again I'm going to meet somebody who is in fact randomizing a 1/3, 1/3, 1/3 over rock, paper, and scissors then with probability 1/3 I'll meet a rock and get 1, with probability 1/3 I'll meet scissors and get -1, and with probability 1/3 I'll meet paper and get 0. Is that correct? Everyone happy with that? So it will net out at 0. </p><p>So each of the pure strategies here rock, paper, or scissors&ndash;actually, I did rock, scissors, and paper, each of them when they play against 1/3, 1/3, 1/3 they yield an expected payoff of 0. What about playing the mix itself? What's the expected payoff of playing--myself playing 1/3, 1/3, 1/3 if I play against somebody who's playing 1/3, 1/3, 1/3? Well, a 1/3 of the time I'm going to be playing rock, so a 1/3 of the time I'm going to be playing rock and then I'll get the expected payoff from playing rock against 1/3, 1/3, 1/3. What was the expected payoff from playing rock against 1/3, 1/3, 1/3? Zero. So, 1/3 of the time I'm going to play rock and I'm going to get this 0. And 1/3 of the time I'm going to be playing scissors, and then I'm going to get the expected payoff from scissors against 1/3, 1/3, 1/3 and what was the expected payoff of scissors against 1/3, 1/3, 1/3? Zero again. So 1/3 of the time I'll play scissors and I'll get this 0. And 1/3 of the time I'll be playing paper, in which case I'll get the expected payoff of paper against 1/3, 1/3, 1/3 which once again is 0. So my total expected payoff is 1/3 of 0, plus 1/3 of 0, plus 1/3 of 0 which, for the math phobics in the room comes, out as 0. </p>
<p>So notice what we've shown here; we've shown that if I play what I claim is the equilibrium strategy 1/3, 1/3, 1/3 against 1/3, 1/3, 1/3 I get 0 and if I played any other strategy I'd still get 0, is that right? So therefore playing 1/3, 1/3, 1/3 is indeed a best response, albeit weakly, it is indeed a best response and this is in fact a Nash Equilibrium. So what we've shown here is in "rock, paper, scissors" playing 1/3, 1/3, 1/3 against the other guy playing 1/3, 1/3, 1/3 is a best response, anything would be a best response, but in particular it's a best response. So if both people play this, one person plays a 1/3, 1/3, 1/3 and the other person plays 1/3, 1/3, 1/3, this is a Nash Equilibrium. So we're belaboring a point that we all knew already: playing 1/3, 1/3, 1/3 against--if everyone plays a 1/3, 1/3, 1/3 that is a Nash Equilibrium. It's a little harder to show but it's true, that that's the only equilibrium in the game. Before you go, if any of you know the people that run ESPN, this is why watching this game on TV is unlikely to be exciting. We'll come back and look at other mixed strategies and more interesting games on Wednesday.</p>
<p></p><p>[end of transcript]</p><p></h2>
  </p>
</div>
<p><a id="backToTop" href="#top">back to top</a></p>