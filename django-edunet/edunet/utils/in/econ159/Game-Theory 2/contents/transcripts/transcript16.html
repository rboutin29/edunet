<div id="fileContents"><h2><strong>Game Theory: </strong>Lecture 16 Transcript</h2><table cellspacing="0" cellpadding="0" id="transcriptHeader" summary="transcript header">	<tbody>		<tr>			<td id="transcriptDate">October 31, 2007</td>			<td id="transcriptNav"><span id="forwardNav"><a href="javascript:history.go(-1);">&lt;&lt; back</a></span></td>		</tr>	</tbody></table></p><p><b>Professor Ben Polak:</b> So this is what we did last time: we looked at a game involving an entrant and an incumbent in a market; and the entrant had to decide whether to enter that market or not; and if they stayed out the incumbent remained a monopolist; and the monopolist made 3 million in profit. If the entrant goes in, then the incumbent can decide whether to accommodate the entrant and just settle for duopoly profits, making a million each; or the incumbent can fight, in which case the incumbent makes no money at all and the entrant loses a million dollars. We pointed out a number of things about this game. One was that when we analyzed it in a matrix form we quickly found that there were two Nash Equilibria, that Nash Equilibrium were: in and not fight; and out and fight. </p><p>But we argued that backward induction tells us that the sensible answer is in and not fight. Once the incumbent knows the entrant is in they're not going to fight because 1 is bigger than 0, and the entrant anticipating this will enter. When we talked a little bit more we said this other equilibrium, this out fight equilibrium--it is an equilibrium because if the entrant believes the incumbent's going to fight then the entrant is going to stay out, and it's costless for the incumbent to "fight" if in fact the entrant does stay out because they never get called upon to fight anyway. </p><p>So the idea of this was that for the incumbent to say they're going to fight is an "incredible threat." That's terrible English. It's the way it is always taught in the textbooks. It needs to be called a "not credible" threat. And that "not credible" threat is: he's not really going to fight if the entrant comes in, and therefore, the entrant should come in and in fact the incumbent will accommodate it. So what we've shown here is that, if we believe this argument, then the entrant will come in and the incumbent is going to let him in. At the end, we started talking about this in a slightly more elaborate setting, so let's just remind you of what that more elaborate setting is. </p><p>The more elaborate setting is suppose that there is one firm, one monopolist, and that monopolist holds a monopoly in ten different markets. So we'll have our monopolist be Ale. So here's Ale. He's our monopolist, and he owns pizzeria monopolies in ten different markets. And each of these ten different markets are separate, they are different towns. And in each of those ten markets he thinks--he knows he's going to face an entrant and those entrants are going to come in order. So let's just talk about who those entrants are going to be. The entrants are going to be this person, this person and so on. Let's find out who they are, so your name is?</p><p><b>Student:</b> Isabella</p><p><b> Professor Ben Polak:</b> Where are you from?</p><p><b>Student:</b> Miami.</p><p><b>Professor Ben Polak:</b> Miami, so Miami is one of the markets. Your name is?</p><p><b>Student:</b> Scott.</p><p><b>Professor Ben Polak:</b> From where?</p><p><b>Student:</b> Wisconsin.</p><p><b> Professor Ben Polak:</b> Where in Wisconsin?</p><p><b>Student:</b> Madison.</p><p><b>Professor Ben Polak:</b> Madison: we've got two towns. We're just going to do towns now.</p><p><b>Student:</b> My name is Lang. I'm from Bridgeport, Connecticut.</p><p><b>Professor Ben Polak:</b> Okay, we've got three towns.</p><p><b>Student:</b> I'm from Miami too.</p><p><b>Professor Ben Polak:</b> Talk about Yale diversity. Well we'll pretend you're from somewhere else. Put him in New Orleans or something.</p><p><b>Student:</b> Chris from Boston.</p><p><b>Professor Ben Polak:</b> From Boston, all right.</p><p><b>Student:</b> From Orange, Connecticut.</p><p><b>Professor Ben Polak:</b> From Orange, Connecticut so just down the road.</p><p><b>Student:</b> St. Louis, Missouri.</p><p><b>Professor Ben Polak:</b> All right, have we got ten yet? I'm not quite at ten. One, two, three, four, five, six, seven.</p><p><b>Student:</b> Saffron, New York.</p><p><b>Professor Ben Polak:</b> All right.</p><p><b>Student:</b> Hong Kong.</p><p><b>Professor Ben Polak:</b> Hong Kong, that's way away.</p><p><b>Student:</b> Long Island.</p><p><b>Professor Ben Polak:</b> Long Island. I think I've probably got ten markets here. So Ale owns a pizza shop. He's the monopoly pizza shop owner in each of these ten markets. And what we're going to see is we're going to see what happens as, sequentially, these entrants try to enter. The way that this game's going to work is that they're lined up--we know the order in which the entrants are going to come. They're going to start off, the first person who is going to have to make a decision is-</p><p><b>Student:</b> Enter. Isabella.</p><p><b>Professor Ben Polak:</b> Is Isabella, right? We're going to see how our monopolist responds. So let's have a look at this. So Isabella who is in which market again?</p><p><b>Student:</b> Miami.</p><p><b>Professor Ben Polak:</b> In Miami, okay what are you going to do?</p><p><b>Student:</b> Enter.</p><p><b>Professor Ben Polak:</b> What are you going to do?</p><p><b>Student:</b> I will fight.</p><p><b>Professor Ben Polak:</b> Oh dear, so you owe me a million dollars. So one person's down a million dollars, let's see what happens next.</p><p><b>Student:</b> I'm going to stay out.</p><p><b>Professor Ben Polak:</b> Which market was this?</p><p><b>Student:</b> Scott. Madison.</p><p><b>Professor Ben Polak:</b> Madison stayed out.</p><p><b>Student:</b> I'm going to stay out.</p><p><b>Professor Ben Polak:</b> Staying out. So Bridgeport stayed out.</p><p><b>Student:</b> I guess I'll stay out.</p><p><b>Professor Ben Polak:</b> Stayed out again.</p><p><b>Student:</b> Stay out.</p><p><b>Professor Ben Polak:</b> Which market are we up to now, somewhere in Orange County wasn't it? Where were we?</p><p><b>Student</b> Orange, Connecticut. Stay out.</p><p><b>Professor Ben Polak:</b> Stay out.</p><p><b>Student:</b> I think I'll stay in.</p><p><b>Professor Ben Polak:</b> You'll come in okay, and which market is this?</p><p><b>Student:</b> St. Louis, Missouri.</p><p><b>Professor Ben Polak:</b> St. Louis, Missouri. So you owe me a&nbsp;million dollars as well, okay. A couple of million dollars is a good class. We're going to have plenty of money for lunch.</p><p><b>Student:</b> I'm also going to fight.</p><p><b>Professor Ben Polak:</b> You're going to fight, which market is that?</p><p><b>Student:</b> Saffron, New York.</p><p><b>Professor Ben Polak:</b> Where abouts?</p><p><b>Student:</b> Saffron.</p><p><b>Professor Ben Polak:</b> Saffron, New York. Where are we at? One, two, three, four, five, six, seven, eight, Ale?</p><p><b>TA:</b> Fight.</p><p><b>Professor Ben Polak:</b> You fight? So you owe me a million dollars too. That was eight, nine?</p><p><b>Student:</b> Out.</p><p><b>Professor Ben Polak:</b> Out and ten?</p><p><b>Student:</b> Stay out.</p><p><b>Professor Ben Polak:</b> Stays out, okay. Now let's just notice something here, which was the tenth market? What town were you?</p><p><b>Student:</b> Long Island.</p><p><b>Professor Ben Polak:</b> Whereabouts in Long Island?</p><p><b>Student:</b> Huntington.</p><p><b>Professor Ben Polak:</b> So if Huntington, Long Island our last market had come in, suppose you'd said in, what would Ale have said?</p><p><b>TA:</b> I would not have fought.</p><p><b>Professor Ben Polak:</b> Would not have fought, aha! Okay, so what happened here? When we analyzed this last time as an individual market, we argued that each entrant should come in just as our first entrant came in, and our monopolist should not fight:. That's what we have up on the board. That's what backward induction suggests. But in fact, Ale fought. A whole bunch of people came in, and a whole bunch of them stayed out, is that right? Now why? Why was Ale fighting these guys and why were they staying out? Let's talk about why, and what market were you again?</p><p><b>Student:</b> Madison, Wisconsin.</p><p><b>Professor Ben Polak:</b> So why did Madison, Wisconsin stay out?</p><p><b>Student:</b> Well we talked about it last time how he has an incentive to fight now because there's more that just our analysis up there in terms of establishing that he'll fight to keep people out.</p><p><b>Professor Ben Polak:</b> All right, so it looks like there might be some reason for fighting to keep you out. So let's just talk about it a little bit more, let's go to the third guy. Which market are you again?</p><p><b>Student:</b> Bridgeport.</p><p><b>Professor Ben Polak:</b> Bridgeport, so why did you stay out?</p><p><b>Student:</b> Because I knew he was going to fight.</p><p><b>Professor Ben Polak:</b> You knew he was going to fight. Now how did you know he was going to fight?</p><p><b>Student:</b> Because he has an incentive to establish, he established that he was going to fight for every single market and so I was going to lose out.</p><p><b>Professor Ben Polak:</b> All right, so we know--we think we know that Ale is--you know he's this tough Italian pizzeria owner and we think he's going to try and establish what: a reputation as being a tough pizzeria owner by fighting these guys, perhaps fighting a few guys early on in order to keep these guys out. In fact, he had to fight the first person but he kept out 2, 3, 4, 5, 6 and this person came in, so 7 and 8 came in, but then 9 and 10 he kept out. So he kept a lot of people out of the market by fighting early on. Now this argument sounds right: it seems to ring true. It's about establishing reputation, but now I want to show you that there's a worry with this argument. </p><p>The worry is this is a sequential game and like all sequential games of perfect information we've seen in the class, we should analyze this game how? Now that wasn't loud enough, how? Backward induction. So where's the back? Where's the back of this game? Way back here--sorry for the guys in the balcony. Way back here we have the last market in town--which was the last market? And if we look at this last market, we in fact saw that if the last market came in, Ale in fact gave in. Ale gave in. Now why did Ale give in, in the last market? Let's have a look back on the board. So on the board we can see what that last market looks like. </p><p>With ten markets this is a very complicated game. This would be the first market, and then there's three versions of the second market depending on what Ale did in the first market, and so there's nine versions of the third one. The tree for this game is horrendous. But nevertheless, once we get to the end of the game, the tenth market--which was what? Bridgeport or something, I've forgotten where it was at now--wherever it was. Once we get to that last market this tree pretty well describes that last market--is that correct? There isn't another market afterwards. There's only ten markets. So, in this last market, what do we know Ale's going to do? In this last market if the entrant enters Ale is going to not fight, which is what exactly what Ale did do. So Ale is that right? So when in fact we discussed the tenth guy coming in, you chose to?</p><p><b>TA:</b> I would have chosen not to fight.</p><p><b>Professor Ben Polak:</b> Would have chosen not to fight. That's exactly what the model predicts. He has no incentive to establish a reputation for the eleventh market because there isn't an eleventh market. He's done at ten. Is that right? So we know that in the last market, the tenth market, Ale actually is not going to fight. Therefore, the person who's the entrant in the tenth market should know that they can safely enter and Ale won't fight them. But now we're in trouble. Why are we in trouble? Well let's go back to the ninth market, the second to last market. So I've forgotten where it was. Raise your hand, the second to the last market. Okay, the second to last market is this guy? You're the tenth market? </p><p>So this guy who is in the Hong Kong market, he should know he's the second to last market. He knows that no matter what he does the tenth market's going to enter and Ale's going to give in to the tenth market. Ale's going to let the tenth entrant in. Is that right? So the ninth market actually knows that nothing Ale's going to do here is going to establish a reputation to keep the tenth guy out. So therefore in fact, he should what? He should come in, right? He should come in, and in fact if he had come in, Ale would have had to give in because there's no way that Ale can keep the tenth guy out. We just argued the tenth guy's coming in by backward induction. </p><p>So since we know that the tenth guy's coming in anyway, and in fact, Ale's going to concede to them, there's no point Ale trying to scare off the tenth guy. So in fact, Ale's going to say no fight to the ninth guy. But now we go to the eighth guy. We've just argued that the tenth guy's coming in anyway and Ale's going to give in to him. We've argued the ninth guy's coming in, so Ale's going to give in to this guy as well because you can't put off the tenth guy. And therefore we know that once we get to the eighth guy, once again, he can safely come in because Ale knows by backward induction he can't keep the ninth and the tenth guy out anyway, and so this guy should come in as well, and if we do this argument all the way back, what do we get? He lets everybody in. Everybody should come in and he should let everybody in. </p><p>So we have a problem here. We have a problem. Backward induction says, even with these ten markets, Ale in fact should let everybody in. Everyone should know that, so they should come in. So there's a disconnect here. There's a disconnect between what the theory is telling us--backward induction is telling us Ale can't keep people out by threatening to fight, by establishing a reputation --, and what we actually just saw, what happened, which was Ale did fight and did keep people out, and we know that other monopolist's do that as well. </p><p>So how can we make rigorous this idea of reputation? It's not captured by what we've done so far in the class. So how can we bring back what must be true in some sense--it's intuition that, by fighting, Ale could keep people out and therefore will keep people out. So to make that idea work I want to introduce a new idea. And the new idea is that, with very small probability, let's say 1% chance, Ale is crazy. So stand up a second, so he looks like a normal kind of guy but there's just 1% chance that he's really bonkers. There's a 1% chance that he's actually Rahul. </p><p>So now let's redo the analysis--And what do I mean by bonkers? By bonkers, I mean, with 1%, Ale is the kind of guy who likes to fight. So with 1% chance, he's actually not got these payoffs at all; he's actually got some different payoffs, which are payoffs of somebody who--okay he'll lose money--but he so much enjoys a fight he gets +10 here. That's the bonkers guy's payoff. But there's only 1% chance he's this bonkers guy. </p><p>So now what happens? Let's just walk it through. With 1% chance, if there was only one market, not the ten markets. So there's only one market and this one market was--I've forgotten your name?</p><p><b>Student:</b> Isabella.</p><p><b>Professor Ben Polak:</b> Isabella, who was in which market, I've forgotten.</p><p><b>Student:</b> Miami.</p><p><b>Professor Ben Polak:</b> In Miami, then she doesn't really much care about the 1% chance that Ale is actually Rahul. That doesn't really bother her very much, why? Because with 99% chance Ale's going to give way and that's good enough odds. With 99% chance she's happy to come in. So if there was only one market here, we'd be done. But with ten markets things are a little different. Why? Let's see why. So suppose in fact that Isabella in Miami thinks that Ale--and everybody else thinks Ale is a pretty sane guy. With 99% probability he's a sane guy, and Isabella enters and everyone sees this. And to everyone's surprise, rather than doing the sane thing, which is letting Isabella in and switching to a duopoly in Miami, what happens, in fact, after Isabella comes in is that Ale fights. Okay, so now it's too late for Isabella, she's lost her money, but our second market is, what's your name again?</p><p><b>Student:</b> Scott.</p><p><b> Professor Ben Polak:</b> Scott, which market were you?</p><p><b>Student:</b> Madison.</p><p><b>Professor Ben Polak:</b> So Scott in Madison has observed what happened in Miami and initially he thought that Ale was Ale. 99% probability Ale was this sane, nice, calm, Italian guy. But on the other hand, he just saw this sane, calm, Italian guy fight, as he shouldn't have fought because of backward induction--fought the entrant in Miami. So now Scott thinks to himself: hmm, I'm not so sure that Ale is this sane guy. Maybe I should update my beliefs in the direction of thinking that Ale might actually be the insane guy. So maybe--we're up to maybe a probability 1/3 that Ale's actually insane. So he thinks: okay, probability 1/3 that's still not very much, I'll still risk it, he comes in, and Ale fights him again. It's a probability 1/3 he's sane. He's going to give in to me. He comes in--Ale fights him again. So now we're in the third market, which was which market?</p><p><b>Student:</b> Bridgeport.</p><p><b>Professor Ben Polak:</b> Bridgeport. And Bridgeport's seen this horrible fight going on in Miami and this horrible fight going on in Madison, and now he's getting pretty sure that this nice, calm, looking Ale is not nice, calm, looking Ale. He's crazy Rahul. There's lot of evidence that he's crazy Rahul. He's fought the last two markets making huge losses. It must be that Ale likes to fight. So what does he do? He says, I'm going to stay out of here. I'm convinced that this guy may be crazy, so I'll stay out. And all the subsequent markets, they think: oh well you know he fought these first two markets, that means he must be a crazy guy or at least there's a high probability that he's a crazy guy, so they all stay out which is exactly what happened until we got to here. And even here when they came in Ale acted liked crazy Rahul. </p><p>So what made that argument possible was what? What made that argument possible was the small possibility, the 1% possibility that Ale is bonkers. But you know, how well do you know Ale? There's a 1% chance he's bonkers. How many of you think you're really sure that he's a sane guy? He supports Italian football teams, he's got to be pretty crazy, right? So what happened here? This small possibility that Ale is crazy allowed him to build up a reputation that kept all these guys out, but actually the argument is stronger than that. Let's try and push this argument harder. </p><p>Suppose, in fact, that Ale is not crazy. Suppose that Ale is the sane Ale, the nice, calm, Ale we all know and love. But we've just argued that if Ale acts as if he's the crazy guy then you're going to be convinced that he is the crazy guy, so by acting crazy he might be able to convince you that he is crazy and therefore keep you out. So we argued before that, if there's some chance that Ale's crazy, by acting crazy early on, he's going to deter these late entrants from entering the market because they think they're fighting Rahul and they don't want to fight Rahul. </p><p>But we said these early guys, they had probability .99 that he was sane; and .6 that he was sane; and maybe even .5 he was sane here--so they thought of coming in. But now we're arguing that even if Ale is sane, even if he's that sane guy, a rational guy, he should behave as if he's crazy in order to keep these late guys out. And these early players knowing that even the sane version of Ale is going to fight them, should also stay out. Now notice something's happened here. They're not staying out because they think Ale's crazy, they're staying out because they know that even the sane version of Ale is going to fight them in order to seem crazy, is that right? Everyone see that's a stronger argument? </p><p>So now even these early guys are going to stay out of the market. Now we're almost there. What we've argued--let's just make sure we get the two pieces of this on the board. We've argued that if there's an epsilon chance, a very small chance, let's call it a 1% chance where Ale is crazy, then he can deter entry by fighting, i.e., seeming crazy. We argued that what really makes this argument strong is once we realize that the sane person's going to act crazy, we really know that everyone's going to act crazy and therefore we should stay out. Now that argument won't quite be right. So that's enough of the argument I want you to have for the purpose of the exam, but let me just point out that that argument isn't quite correct. That can't quite be an equilibrium. Now why can't that be an equilibrium? </p><p>We've just argued that even the sane version of Ale--so this is a sort of slightly more subtle argument so just pay attention a second. We've argued that even the sane version of Ale is going to act like a crazy guy. So if anyone came in, he's going to act crazy anyway. So you're not going to update your belief as to whether he's crazy or sane because we know that the crazy guy is going to fight because he likes fighting and the sane guy is going to fight because he wants to seem like a crazy guy. So you're really learning nothing whether your observe him fighting or now. </p><p>But now let's go back to our tenth market, way back in our tenth market. Our tenth market participant, whose name was Andy, hasn't learned anything about Ale. He hasn't learned anything because whether Ale was sane or crazy he's going to fight. So observing what his actions early on, if that was really an equilibrium, our tenth guy wouldn't have updated his belief at all, and therefore, would still believe with probability .99 that Ale was sane, in which case our tenth guy would enter. Once again, that argument would unravel from the back. So what I described before can't quite be an equilibrium. It can't be just as simple as all sane guys are going to act crazy because then you wouldn't learn anything. </p><p>So it turns out that the equilibrium in this model is actually very subtle, and it involves mixed strategies, and mixed strategies are something we did in the first half of the semester, so we don't want to go back to it now. So trust me, you can solve this out with mixed strategies and the basic idea I gave you is right. The basic idea is sane guys are occasionally going to act like crazy guys in order to establish a reputation, and that reputation helps them down the tree. </p><p>So this idea that even when there's a chain store, people will enter--even when Ale has ten monopolies, people will enter--this is a famous idea. It's called the Chain Store Paradox, and it's due to a guy called Selten who actually won the Nobel Prize. This is the Chain Store Paradox and this idea of establishing reputation is a big idea. The idea is once again you might want to behave as if you're someone else in order to deter people's actions, in order to affect people's actions down the tree. Okay, so what have we learned here? Let's just work it out. So the first thing we learned was kind of a nerdy point, but let me make it anyway. Introducing just a very, very small probability, just a tiny probability that Ale might be someone else--he might be a Rahul, he might be crazy, he must like fights--that very small probability radically changes the outcome of the game. If we were all 100% sure he was sane we'd be tied by backward induction and entry would follow. He wouldn't be able to keep anybody out. But that small probability allows us to get a very different outcome. That's the first point I want to draw into this. </p><p>The second point I want to get out of this, is really this idea of reputation. There are lots of settings in society where reputation matters and one of them is a reputation to fight. How many of you have friends who have somewhat short fuses? You know people who have short fuses, right? When you're going out, choosing some movie to go to with these guys who have short fuses or trying to decide who's going to order something at a restaurant, or who's going to get to be which side when you're playing some game, some video game. I claim, is this true, that the people who have slightly short fuses, slightly more often get their way, is that right? </p><p>If you have a sibling who has a short fuse, they slightly more often get their way and that's exactly this idea. They have short fuses, the fact that they tend to blow up and get angry at you gives them a little bit of an advantage. And notice that maybe they don't have a short fuse at all, maybe they're just pretending to have a short fuse because they know they're going to get their way over you softies more often. None of you have short fuses, you're all sane people right? So this idea, it should be a familiar idea to you, but it's not just an idea in the sort of trivial world of bargaining. Notice this idea of reputation occurs all over the place. </p><p>So another place it occurs, somewhat grim place it occurs, is in the subject of hostage negotiations. In the subject of hostage negotiations, when some other country has seized some hostages from the U.S. or maybe some criminal organization has seized some members of your family or some members of your community and is holding the hostages, there's a well known idea which is what? Which is that you should never negotiate with hostage takers, is that right? Everyone's heard that idea? You should never negotiate with hostage takers. You never give in just because they have hostages. Why? </p><p>It's the same idea: because you want to have a reputation for being somebody who doesn't give in to hostage takers in order to deter future potential hostage takers from taking hostages. This has grim consequences but sometimes it's worth bearing the cost of having your relatives come back in pieces in order to deter future relatives from being taken. So that's a somewhat macabre version of this. Let me give you one other version. There are whole areas of the economy where reputation is crucial, where if people played according to their backward-induction, sane incentives, we'd have a disaster. </p><p>But having a reputation here isn't necessarily a reputation as a tough guy. It could be a reputation for somebody who's a nice guy. Could be that you want to have a reputation for being the sort of person who derives pleasure or utility from, (quote) "doing the right thing," from acting honestly. So think about certain professions where the reputation of the person in the profession is crucial. Doctors, for example: it's crucial for a doctor that he or she has the reputation of someone who tells the truth. Otherwise, you'd stop going to that doctor. </p><p>Accountants: accounting firms rely on having a reputation for being honest and not cheating the books. When they stop having that reputation for being honest--think of Arthur Anderson after the events in Enron--they pretty quickly cease to be in business. I gave that example a couple of years ago, and it was very embarrassing because it turned out Arthur Anderson was in the class--literally Arthur Anderson III was in the class. These things happen at Yale. But nevertheless, Arthur Anderson relied on his reputation, the firm relied on its reputation as an honest firm, and it was worth behaving honestly to maintain that reputation for future business. </p><p>Reputation is a huge topic and my guess is that the next time there's a Nobel Prize in game theory it'll be for this idea. So that's my prediction. Now having said that, I want to spend the whole of the rest of today playing one game and analyzing one game. So we're going to play this game and for this game I need a couple of volunteers. So I'm going to pull out some volunteers. Anyone want to volunteer? I need two volunteers for this game. How about my guy from the football team, was that a raised hand? It wasn't a raised hand, how about my guy from the football team? Is it football team? Baseball team, that may be unfair in this particular game. Maybe I'll take someone who isn't on the baseball team. Anyone who's on the football team? These guys, you guys on the football team? Okay great, so you two guys. </p><p>I need you at the front and your names are? Chevy and Patrick. So Chevy and Patrick are going to be our volunteers. Now the idea of this game is you guys provided the volunteers--wait down here a second--you guys provided the volunteers. This game involves two volunteers that you just provided, and two wet sponges. I will provide the wet sponges. So I have here a couple of sponges and in a minute I'm going to wet them, and I'll tell you what the rules are in a second. Okay, so I'm going to give one of these sponges each to Chevy and Patrick, and then going to position Chevy and Patrick at either end of this central aisle, of this aisle here, and the game is going to be as follows. It's important that everyone listen to the rules here because I'm going to pick two more volunteers in a moment. </p><p>So the game they're going to play is as follows. Each of them has one sponge. It's crucial they only have one sponge. And they're going to take turns. And when it's your turn, as long as you still have your sponge in your hand, you face a choice. You can either throw your sponge at your opponent, and if you hit your opponent you win the game, or you have to take a step forward. So either you throw the sponge or you take a step forward. Now there's a crucial rule here. Each player only has one sponge and, once they've thrown that sponge, they do not get the sponge back. Everyone understand that? Once you've thrown the sponge you do not get the sponge back. </p><p>So once again, if you throw your sponge at your opponent and you hit your opponent then you've won the game. But if you throw your sponge at your opponent and you miss, the game continues. So let's make sure we understand that, if you throw your sponge and miss the game continues:. You still have to step forward. So, what's your opponent going to do at that point? What's your opponent going to do? Let's make sure that our football players understand this. It wasn't meant that way. They could have been soccer players, come on. </p><p><b>Student:</b> I didn't appreciate that very much</p><p><b>Professor Ben Polak: </b>I'm sorry I didn't mean it that way. So if your opponent whose name is Patrick throws and misses, what are you going to do?</p><p><b>Student:</b> I'll walk forward until I slam the sponge in his face.</p><p><b>Professor Ben Polak:</b> Great, you will walk forward until you politely put it on his head. Everyone understand? That, if in fact, you throw and miss you've lost the game, because the other guy can wait until he's standing right on top of you and just place the sponge gently on his head. Now for fairness sake, it's important that these sponges are equally weighted, and I'm going to weight them--I'm going to put water in them now. And--you know nothing but the best for Yale students--I'm going to provide Yale University spring water. Who knew that Yale University had a spring. That's kind of a strange one? If it makes you feel better you can think of this American beer. </p><p>I'm not going to make these too heavy, partly because it makes it too easy and partly because I don't want to get sued. So I'm going to squeeze these out somewhere away from the wires. We're going to get our judge here to weigh them, I need a mike here, let me get a mike. So I'll need you to hold those sponges in your hands and tell me if they're equally weighted. Pretty equal? Okay, they're pretty equal, everyone agrees. So how is this going to work? I'm going to give the blue sponge to Chevy and the green sponge to Patrick. And Chevy's going to stand here, and Patrick's going to stand as far back as I can get him on camera, which I'm going to be told how far back I can go. Don't go too far. Okay come back Patrick, you're too ambitious. Come back. Keep coming. stop. Okay, we're going to start here--start quite close actually. Everyone understand how we're going to play this? So Chevy is Player 1, Patrick is Player 2. Chevy has to decide whether to throw or to step.</p><p><b>Student:</b> I'll step.</p><p><b>Professor Ben Polak:</b> Okay, let's just hold the game a second. Now its Patrick's turn. Does anyone have any advice for Patrick at this point? If you think throw, raise your hand. If you think step, raise your hand. There's a lot more steps than throws. I thought the Yale football team was good this year. Your choice, step or throw. I should announce two other rules. It's kind of important I should have said this. First, a step has to be a proper step, like a yard long; and second (I think this will work in America): gentleman never duck. No dodging the sponge okay. Chevy: your turn.</p><p><b>Student:</b> I don't really trust my arm. I'm going to step.</p><p><b>Professor Ben Polak:</b> All right, so you're stepping again. Let me go to Patrick. I feel like I'm in the line of fire here. Patrick what are you going to do?</p><p><b>Student:</b> I'm going to throw.</p><p><b>Professor Ben Polak:</b> Patrick's going to throw, I'm really going to get out of the way then. We'll see this in slow motion. </p><p>Continue, all right so you have to take a step forward, so Chevy's going to take a step forward I assume? Patrick's going to take a step forward. Chevy's going to take a step forward. Patrick's going to take a step forward. </p><p>Good, so a round of applause for our players, thank you. So I think we have time to do this once more, and then we're going to analyze it. So I want to get two women involved. It's too sexist otherwise. So can we have two women in the class please? Two volunteers, come on, you can volunteer. There's a volunteer. Thank you great. Okay great, thank you. So your name is?</p><p><b>Student:</b> Jessica.</p><p><b>Professor Ben Polak:</b> Jessica and your name is?</p><p><b>Student:</b> Clara-Elise.</p><p><b>Professor Ben Polak:</b> Clara-Elise and Jessica. We'll start at the same positions, we'll use the same sponges, and I just need to remind you where that position was. Just give me a thumbs up when I'm in the right position. Good, same rules, Clara-Elise and Jessica. We'll let Jessica be Player 1. So Jessica you can step or throw, what do you want to do?</p><p><b>Student:</b> I'm going to step.</p><p><b>Professor Ben Polak:</b> Going to step, okay. You know what might be a good idea: Ale why don't you put the mike on Clara-Elise. So we have a mike at either end rather than running to and fro, that's good. So Clara-Elise what are you going to do?</p><p><b>Student:</b> I'm going to step.</p><p><b>Professor Ben Polak:</b> You're going to step and Jessica what are you going to do?</p><p><b>Student:</b> I'm going to step.</p><p><b>Professor Ben Polak:</b> You're going to step. Ale and I are in danger here but never mind. Any votes now? Do people think that Jessica should throw? If you think she should throw raise your hands. There's a large majority for step. So up to you, what are you going to do?</p><p><b>Student:</b> I'm going to step.</p><p><b>Professor Ben Polak:</b> Going to step okay. Clara-Elise any decisions? It's a pretty light sponge, It's pretty hard to throw the sponge, because we've seen that. Okay, stepping again.</p><p><b>Student:</b> I'm going to throw.</p><p><b>Professor Ben Polak:</b> You're going to throw okay, here we go, let me get out of the way. </p><p>Oh okay, continue please. Clara-Elise's turn.</p><p><b>Student:</b> I'll step.</p><p><b>Professor Ben Polak:</b> You'll step. Jessica has to step, Clara-Elise has to step, all right good. </p><p>So we've seen how the game works, everyone understands how the game works. I want to spend the rest of today analyzing this game. Before I do so, we should just talk about what this game is. Let me get some new boards down here. So one quick announcement: I'm going to analyze this, and we're going to spend the rest of today analyzing this, but this is going to be quite hard. So I'm going to provide you a handout that I'll put on the web probably tomorrow that goes over this argument. So you don't have to take detailed notes now, I want you to pay attention and see if you can follow the argument. </p><p>So this game is called duel, not surprisingly, and you may wonder what are we doing--as are my colleagues that are here--what are we doing having a duel in class. Of course one answer to that is, it's kind of fun watching the future leaders of America throw wet sponges at each other. That's probably reason in itself. But there are other reasons. Duel is a real game. So those of you who are well versed in Russian literature will have seen duals before, or at least read of duals. There are some famous duels in Russian literature. Anyone want to tell me some famous duels in Russian literature? Any Russian majors here? No, nobody want to give me a shot at this? Really nobody. This is Yale, come on. </p><p>Well, how about in War and Peace okay. There's a duel like this in War and Peace, and in War and Peace and without giving away the ending--actually it's in the middle of the book and it's 800 pages long, so it isn't exactly the ending. But in War and Peace I think we're led to believe that the hero, the protagonist Pierre, shoots his gun--in War and Peace it's a gun and not a sponge, no surprise--he shoots his gun too early, we're led to believe. There's a famous one in Eugene Onegin, in Pushkin's Eugene Onegin, and there are lots of others actually, so there's lots in literature. </p><p>There are also settings which aren't exactly out of literature. So one example would be in a bike race. How many of you ever watch the Tour de France? Everyone know what I mean by the Tour de France. So this is a bike race that goes around France. It takes stages. And in the Tour de France, there's a key decision. There's a game within the game, and the game within the game--I'm looking at Jake who's a real cyclist here--but the game within the game is when do you try to break away from the pack, which is called the peloton. And if you break away too early from the peloton, it turns out that you're going to get reeled in. It turns out that over the long haul the peloton can go much faster than you. So if you break too early they're going to catch you up. </p><p>On the other hand, if you break too late, then you're going to lose because there are going to be some people in the peloton who are just excellent sprinters. So if you break too late the sprinters are going to win the race. So you have to decide when to break from the peloton. This is the second most important game within a game in the Tour de France, the most important game within a game is where to hide your steroids. So let me give you one other example. </p><p>Let me give you a more economic example--it's meant to be an economics class. Imagine there's two firms, and these two firms are both engaged in R&amp;D, research and development. And they're trying to develop a new product, and they're going to launch this new product onto the market. But the nature of this market is--maybe it's a network good--the nature of this market is there's only going to be one successful good out there. So essentially there's going to be one standard, let's say of a software or a technological standard, and only one of them is going to survive. The problem is you haven't perfected your product yet. If you launch your product too early it may not work, and then consumers are never going to trust you again. But if you launch it too late the other side will have launched already, they will have got a toehold in the market, and you're toast. </p><p>So that game--that game about product launch--is like duel, except you're launching a product rather than launching a sponge. Is that right? Now all of these games have a common feature, and it's a new feature for us. It's about the nature of the strategic decision. In most of the games we've looked at in the course so far the strategic decision has been of the form: where should I locate, how much should I do, what price should I set, should I stand for election or not? Here the strategic decision is not of the form what should I do. It's of the form what? When? It's of the form <i>when</i> am I going to launch the sponge? We know perfectly well what you're going to do. You're going to throw the sponge. The strategic issue in question is when. So the issue here is when. </p><p>So to analyze this, I'm going to need a little bit of notation, and let me put that notation up now. So in particular, I want to use the notation, Pi[d] to be what? Let Pi[d] be Player i's probability of hitting if i shoots at distance d. So Pi[d] is the probability that i will hit if he or she shoots at distance d. Everyone happy with that? That's the only notation I'm going to use today. And I'm going to make some assumptions about the nature of this probability. Two of the assumptions are pretty innocent. So let's draw a picture. So the picture is going to look like this. Here's a graph, and on the horizontal axis I'm going to put d. This is the distance apart of the two players. And on the vertical axis I'm going to put P which is the probability, Pr the probability. </p><p>So here they're at distance 0, and I'm going to make an assumption about what the probability of hitting is if you're at distance 0. What's the sensible assumption? What's the probability of hitting somebody with your sponge if you're 0 distance away? 1, okay, I agree, so 1. So the first assumption I'm going to make is, if they're right on top of each other, they're going to hit with probability 1. Now the second assumption I'm going to make is: as you get further away this probability decreases. It doesn't have to look exactly like this but something like that. That also I think--Is that an okay assumption? As you're further away there's a lower probability of hitting. Now I'm not going to assume that these two players have equal abilities. </p><p>For example, I don't know; I didn't ask them but one of our two football players might be a quarterback and the other one might be a linebacker or a running back. And I'm assuming the quarterback is probably more accurate, is that right? So I'm not going to assume that they're equally good, so it could be that their abilities look like this. This could be P1[d], and this could be P2[d]. Everyone okay with that? So shout this out, in this picture, who is the better shot and who is the less good shot? Who is the better shot? 1 is the better shot because at every distance if Player 1 were to throw, Player 1's probability of hitting is higher than Player 2's probability of hitting as drawn. </p><p>Now, I don't even need to assume this. It could well be that these probabilities cross. It could be that these curves cross. So it could be that Player 1 is better at close distances, but Player 2 is better at far distances. That's fine. We'll assume it's like this today but I'm not going to use that. I could do away with that. As drawn, Player 1 is the better shot. Now I'm going to make one assumption that matters, and it's really a critical assumption. I'm going to make the assumption because it keeps the math simple for today. We have enough math to do anyway. I'm going to assume that these abilities are known. I'm going to assume that not only do you know your own ability of hitting your opponent at any distance. I'm going to assume you also know the ability of your opponent to hit you. </p><p>Now let's look at this a second. We've got a little bit of notation on the board, let's discuss this a second. What do we think is going to happen here? In this particular example we have a good shot and a less good shot. Who do we think is going to shoot first? Let's try and cold call some people. So you sir what's your name?</p><p><b>Student:</b> Frank.</p><p><b>Professor Ben Polak:</b> Frank, so who do you think is going to shoot first, the better shot or the worse shot?</p><p><b>Student:</b> The better shot but also depends on who steps first.</p><p><b>Professor Ben Polak:</b> Okay, let's assume Player 1 is going to step first.</p><p><b>Student:</b> Player 1.</p><p><b>Professor Ben Polak:</b> So Frank thinks Player 1 is going to shoot first because Player 1 is the better shot. Let's see, so what's your name?</p><p><b>Student:</b> Nick.</p><p><b>Professor Ben Polak:</b> Nick, who do you think is going to shoot first?</p><p><b>Student:</b> I think Player 2 would shoot first.</p><p><b>Professor Ben Polak:</b> All right, so let's talk why. Why do you think Player 1 was going to shoot first? Let's do a poll. How many of you think the better shot's going to shoot first? How many people think the worse shot's going to shoot first? How many people of you are being chickens and abstaining? Quite a few okay. So why do we think the better shot might shoot first?</p><p><b>Student:</b> At equal distance, he has a better chance of hitting.</p><p><b>Professor Ben Polak:</b> Because he has a better chance of hitting, but why do you think that the less good shot might shoot first?</p><p><b>Student:</b> He knows that if P1 gets too close he's going to win anyway, so he may as well take a shot with lower chance before P1.</p><p><b>Professor Ben Polak:</b> All right, okay so you have two arguments here, the first argument is maybe the better shot will shoot first because, after all, he has a higher chance of hitting. And the other argument says maybe the worse shot will shoot first, to what? To pre-empt the better shot from shooting him. But now we get more complicated, because after all, if you're the better shot and you know that the worse shot maybe going to try and shoot first to try and pre-empt you from shooting him, you might be tempted to shoot before the worse shot shoots to preempt the worse shot from pre-empting you from shooting him. And if you're the worse shot maybe you're going to try and shoot first, even earlier, to pre-empt the better shot from pre-empting the worse shot, from pre-empting the better shot from shooting the worse shot and so on. </p><p>So what's clear is that this game has a lot to do with pre-emption. Pre-emption's a big idea here, but I claim it's not at all obvious who's going to shoot first, the better shot or the worse shot. Is that right? So those people who abstained raise your hands again. Those people who abstained before, it seemed like it was a pretty sensible time to abstain. It's not obvious at all to me who's going to shoot first here. Are people convinced at least that it's a hard problem? Yes or no, people convinced? Yeah okay good. It's a hard problem. So what I want to do is, as a class, as a group, what I want us to do is solve this game; and I want to solve not just who is going to shoot first, I want to figure out exactly when they're going to shoot. </p><p>So we're going to do this in the next half hour and we're going to do it as a class, so you're going to do it. So we're going to nail this problem basically, and we're going to do it using two kinds of arguments. One kind of argument is an argument we learned the very first day of the class and that's a dominance argument, and the second kind of argument is an argument we've been using a little bit recently, and what kind of argument is that? What is it? Backward induction. So we're going to use dominance arguments and backward induction, and we're going to figure out not just whether the better shot or the worse shot's going to shoot, but exactly who's going to shoot when. Let's keep our picture handy, get rid of, well I can get this down I guess. Can you still see the picture? </p><p>All right, let's proceed with this argument. So to do this argument, I first of all want to establish a couple of facts. I want to establish two facts, and we'll call the first fact: Fact A. Let's go back to our two players we had before. In fact, maybe it would be helpful to have our players. Can I use our first two players as props. Can I have you guys on stage? While they're coming up--sorry guys, I'm exploiting you a bit today. I hope you both signed your legal release forms. Why don't you guys sit here a second so I can use you as props. </p><p>So imagine that these two guys still have their sponges. Let's actually set this up. So suppose that Chevy still has a sponge, and Patrick still has his sponge. And suppose it's Chevy's turn, and suppose that Chevy is trying to decide whether he should throw his sponge or not. Let me give you a mike each so you have them for future reference. So Chevy is trying to decide whether to throw his sponge or not. Now suppose that Chevy knows that Patrick is not going to shoot next turn when it's his turn. So Chevy's trying to decide whether to shoot and he knows that Patrick is not going to shoot next turn when it's his turn. What should Chevy do? Chevy what should you do?</p><p><b>Student:</b> Take a step.</p><p><b>Professor Ben Polak:</b> Take a step, that's right. Why should he take a step? What's the argument? Why he should take a step? Well let's find out: what's the argument? </p><p><b>Student:</b> Because I'll just be one step closer and I'll be able to make the same choice next time.</p><p><b>Professor Ben Polak:</b> Good, hold the mike up to you. You're a rock star now. All right good, he's correctly saying he should wait, why should he wait? Because he's going to be closer next time. So the first fact is: assuming no one has thrown yet, if Player i knows (at (say) distance d) that j will not shoot--let me call it tomorrow; and tomorrow he'll be closer, he'll be at distance d - 1--then Chevy correctly says, I should not shoot today. Again, recall the argument, the argument is you'll get a better shot, a closer shot, the day after tomorrow. </p><p>Now, let's turn things around. Suppose, conversely--once again we're picking on Chevy a second--so Chevy has his sponge. No one has thrown yet, and suppose Chevy knows that Patrick <i>is</i> going to throw tomorrow. Now what should Chevy do? Well that's a harder decision. What should Chevy do? He knows Patrick's going to shoot tomorrow. What should he do? Should he shoot or what, what's the answer this time? What do you reckon?</p><p><b>Student:</b> It depends.</p><p><b>Professor Ben Polak:</b> It depends. I think that's the right answer: it depends. Good, so the question is--someone else, I don't want to pick entirely on these guys--so what does it depend on? It's right that it depends. What does it depend on? </p><p><b>Student:</b> If the other guy's chances are greater than or less than 50%.</p><p><b>Professor Ben Polak:</b> All right, so it might depend on the other side's chances being less than or great than 50%. It certainly depends on the other guy's ability and on my ability. Everyone clear on that? Everyone agrees whether I should shoot now if I know the other guy is going to shoot tomorrow depends on our abilities, but how exactly does it depend on our abilities?</p><p><b>Student:</b> It depends on: if you're probability to hit is greater than his probability to miss.</p><p><b>Professor Ben Polak:</b> Good, your name is?</p><p><b>Student:</b> Osmont</p><p><b>Professor Ben Polak:</b> Osmont. So Osmont is saying--let's be careful here: it depends on whether my probability of hitting if I throw now is bigger than his probability of <i>missing</i> tomorrow. And why is that the right comparison? That's the right comparison because, if I throw now, my probability of winning the game is the probability that I hit my opponent. If I wait and take a step, then my probability of winning the game is the probability that he misses me tomorrow. So I have to compare winning probabilities with winning probabilities: I have to compare apples with apples, not apples with oranges. </p><p>Everyone see that? Okay, so let's put that up. So the same assumption: assuming no one has thrown, if i knows (at d) that j <i>will</i> shoot tomorrow (at d--1), then i should shoot if--need a gap here--if i's probability of hitting at d--and let me leave a gap here--is bigger than or equal to--it doesn't really matter about the equal case--is greater than or equal to j's probability of missing tomorrow. Because this is the probability that you'll win if you throw, and this is the probability that you'll win if you wait. Okay, so let's put in what those things are. So the probability that i will hit at distance D, that's not that hard, that's Pi[d]--everyone happy with that? What's the probability that j will miss tomorrow if j throws? What's the probability that j will miss? Somebody? Let's be careful, so it's 1--Pj--but what distance will they be at--d--1: so it's (1--Pj[d--1]). </p><p>So this is the key rule, if Chevy knows that Patrick's going to shoot tomorrow then Chevy should shoot if his probability of hitting Pi[d] is bigger than Patrick's probability of missing (1 - Pj[d--1]). Now I want to do one piece of math. This is the only math in this proof. So everyone who is math phobic, which I know there is a lot of you, can you just hold onto your seats? Don't panic: a little bit of math coming. This is the math, I want to add Pj[d--1] to both sides of this inequality. That's it, so what does that tell me? If add Pj[d -1] to this side, I get +Pj[d--1], everyone happy with that? On the other side if I add Pj[d--1], I get just 1. Everyone happy with that? </p><p>So here's our rule, our rule is, let's flip it around, if Patrick hasn't thrown yet and thinks that Chevy's going to shoot tomorrow then Patrick should shoot now if his probability of hitting now plus Chevy's probability of hitting tomorrow is bigger than 1. Let's call this * and let's put this stuff up somewhere where we can use it for future reference. Sorry guys, I'll use you again in a minute. I know you're feeling self conscious up there. Believe me, I'm self conscious up here too. So let's look at that * inequality up there. Now way out here, is that * inequality met or not met? It's not met because way out here these two probabilities are small, so the sum is less than 1. In here, is the * inequality met or not met? Let me pick on you guys, so Patrick is it met or not met in here? Shout into your microphone.</p><p><b>Student:</b> It's met.</p><p><b>Professor Ben Polak:</b> It's met, thank you okay. So, in here, the inequality is met: the sum is bigger than 1; and out here it's less than 1. If we put in all the steps here--here they are getting closer and closer together. Here's the steps, as they get closer and closer together. We put these steps in. There's going to be some step where, for the first time, the * inequality is met. Notice that they start out here, they get closer and closer, it's not met, not met, not met, not met, not met, not met, then suddenly it's going to met. Maybe around here. Let's just try and pick it out, maybe it's here. So this might be the first time that this * inequality is met, let's call it d*. </p><p>Everyone understand what D* is? At every one of these steps to the right of d*, when we take the sum of the probability Pi[d] + Pj[d--1], we get something less than 1. But to the left of d* or closer in than d*--the game is proceeding this way because it's moving right to left, they're getting closer and closer--to the left of d* the sum of those probabilities is bigger than 1. Let's say that again, d* is the first step at which the sum of those two probabilities exceeds 1. Everyone okay about what d* is? Anyone want to ask me a question? Okay, people should feel free to ask questions on this, I want to make sure everyone is following. Is everyone following so far? Yeah? I need to see all your eyes. You don't look like you're stuck in the headlamps like you were on Monday. I think we're better off than we were on Monday. Good okay. </p><p>Okay, so here's our picture, and I actually want a bit more space--I'm not going to have much more space. So now I'm going to tell you the solution. The solution to this game is this. I claim that the first shot should occur at d*. So that's my claim. No one should shoot until you get to d*, and whoever's turn it is--whether it's Chevy's turn or Patrick's turn at d*--that person should shoot. That's my claim, and that's what we're going to prove. Everyone understand the claim? It says: nobody shoots, nobody shoots, nobody shoots, nobody shoots, nobody shoots, nobody shoots, shoot. Let's prove it, everyone ready to prove it? </p><p>Yeah, people should be awake. If your neighbor's not awake, nudge them hard. Good, all right, let's start this analysis way out here, miles apart. These guys are miles apart and I want to use them as props. So I've got these guys--stay where you are Patrick but stand up, and Chevy over here somewhere, just where that black line is. Maybe they're even further than this. They're really far apart. And here they are miles away, and let's say it's Chevy's turn. He's way out here: perhaps the first step of the game. Imagine it's even further because it was even further, and let's think through what should be going on in Chevy's head. There are two possible things going on. He's going to think about what Patrick's going to do. So this is Chevy's turn. Here he is. And he should think: tomorrow, it's going to be Patrick's turn, and there's two possibilities. </p><p>One possibility is that Patrick is not going to shoot tomorrow. And if we think that Patrick is not going to shoot tomorrow, which fact should Chevy use? Should he use Fact A or Fact B? Chevy which fact should you use?</p><p><b>Student:</b> Fact A.</p><p><b>Professor Ben Polak:</b> Fact A, okay. So, using Fact A, he should not shoot. Alternatively, he could think that Patrick's going to shoot tomorrow, is that right? He could think Patrick's going to shoot tomorrow. If he thinks Patrick's going to shoot tomorrow, which fact should he use? B. He should use Fact B, in which case he has to look at this inequality up here and say, I'll shoot if my probability of hitting now plus his probability of hitting tomorrow is bigger than 1. Well let's have a look. </p><p>This is Patrick's probability of hitting today and this is Chevy's probability of--sorry--this is Chevy's probability of hitting today, and this is Patrick's probability of hitting tomorrow. And is the sum of them bigger than 1 or not? Is it bigger than 1 or not? It's not bigger than 1. So what should Chevy do? He should step. So he'd step. Now it's Patrick's turn, and once again, imagine this distance is still pretty large, and there's two things Patrick could think. Patrick could think that Chevy's not going to shoot tomorrow. So here's Patrick, he's looking forward to Chevy tomorrow, and he could think that Chevy's not going to shoot tomorrow. If he thinks Chevy's not going to shoot tomorrow which fact should he choose?</p><p><b>Student:</b> A.</p><p><b>Professor Ben Polak:</b> Should choose Fact A, okay. If he's using Fact A, he should not shoot. Alternatively, he could think that Chevy is going to shoot tomorrow, in which case he uses Fact B, and what does he do? He adds up his probability, Patrick's probability of hitting today plus Chevy's probability of hitting tomorrow: he asks is that sum bigger than 1, and he concludes, no. So we have no shot here and no shot here, and notice that both of those arguments were dominance arguments. In each case, whether Chevy thought that Patrick was going to shoot tomorrow or not, in either case, he concluded he should not shoot today. When it was Patrick's turn, whether Patrick thought that Chevy was going to shoot tomorrow or not, in either case, he concluded he should not shoot today. So he takes a step forward. </p><p>This argument continues, it'll be Chevy's turn next, and once again he'll look at these two possibilities. If he thinks Patrick's not shooting tomorrow, he wants to step, if he thinks Patrick is going to shoot tomorrow, he's again going to want to step the way it's drawn. And, once again, we'll conclude step. We'll go on doing this argument, and everyone see that in each case this dominance argument will apply. It won't matter whether I think you should shoot tomorrow or not, in either case, it'll turn out that I should step forward: whether Fact A applies or whether Fact B applies, So we'll go on going forward and we'll have: no shot, no shot, no shot, no shot, no shot, no shot, and we'll arrive at d*. </p><p>So it turns out that d* is going to be Chevy's turn again. At d* we try exactly the same reasoning. At d* he says, if I think Patrick is not going to shoot tomorrow what should I do? What should I do if I think Patrick's not going to shoot tomorrow?</p><p><b>Student:</b> Not shoot.</p><p><b>Professor Ben Polak:</b> Not shoot. But now something different occurs. Now he says, if I think Patrick is going to shoot tomorrow, then when I look at my inequality up there, my * inequality, and add up my probability of hitting today--which is this line here--plus Patrick's probability of hitting tomorrow--which is this line here--suddenly he finds it is bigger than 1. So now if Chevy thinks that Patrick is going to shoot tomorrow, what should Chevy do? He should shoot. So up until this point, a dominance argument has told us no one should shoot, but suddenly we have a dilemma. The dilemma is: if Chevy thinks Patrick's not shooting, he should step; and if Chevy thinks Patrick is shooting, he should shoot. </p><p>Everyone with me so far? So what have we shown so far? We've shown that no one should shoot until d* but we're stuck because we don't know what to do at d*; because we don't know what Chevy should believe at d*. We don't know whether Chevy should believe that Patrick's going to shoot or whether Chevy should believe that Patrick's not going to shoot. So how do we figure out what Chevy should believe Patrick's going to do? Wait, wake up the guy in orange there, the guy with the ginger hair, that's right. What's the answer to that question? Good, the answer to the question is backward induction. </p><p>Round of applause for remembering the answer. Good, backward induction is the answer to all questions, especially when you're asleep right. Okay, so now we're going to use backward induction, but where does backward induction start here? Backward induction starts at the back of the game, and what's the back of the game here? The back of the game is where? It's when these two guys, neither of them have thrown their sponge, and they've reached here. So come here a second, step, step. Let's assume it's Patrick's turn, and they're absurdly close: they're uncomfortably close. If they had longer noses they'd be touching. They're at distance 0. And at distance 0, at d = 0, let's suppose it's Patrick's turn. So at d = 0, no one has shot, it's Patrick's turn, he's got the sponge, what should Patrick do? Shout it out Patrick.</p><p><b>Student:</b> I should shoot.</p><p><b>Professor Ben Polak:</b> You should shoot. Patrick should shoot, right? At d = 0, say it's 2's turn, and the answer is he should shoot because the probability of it hitting at distance 0 is 1. Let's just move you to the side a bit so that people can see the board. I know it's an awkward dance but here you are--stop there: that's good. So at distance 0 they should certainly shoot. So now let's go back a step in the backward induction. So we're at distance 1, just take a step back. So take a step back, it's Chevy's turn at distance 1. And what does Chevy know at distance 1? Chevy what do you know? Shout it out.</p><p><b>Student:</b> That Patrick will shoot next turn.</p><p><b>Professor Ben Polak:</b> Right, so now Chevy knows that Patrick's going to shoot tomorrow. So which fact should Chevy use in deciding whether he should shoot today? B. He should use Fact B, and that tells us--so 1 knows that 2 will shoot tomorrow, so by B, 1 should shoot if his probability of hitting at distance 1 plus Patrick's probability of hitting at distance 0, if that is bigger than 1. Well is it bigger than 1? Well let's have a look. </p><p>We had a shot in here already, we put a shot in here, and we're looking at distance 1. And so we're looking at this distance here plus this distance here. Is it bigger than 1? Yeah, it's bigger than 1. Here's a bit more math. I lied to you before. 1 plus something is bigger than 1. So this is bigger than 1. So shoot. Let's put it on our chart as shoot. Let's go back a step--sorry--I'll have to have Chevy do all the going backwards. Now we're at distance what? We're at distance 2, we're at d = 2, and it's Patrick's turn, 2's turn, and what does Patrick know? Shout it out Patrick.</p><p><b>Student:</b> I know that Chevy's going to shoot next turn.</p><p><b>Professor Ben Polak:</b> Patrick knows that Chevy's going to shoot next turn, so Patrick therefore should use which fact? Fact B. And Fact B tells him that he should shoot--let's just put this in. So 2 knows that 1 will shoot tomorrow, so by B it's all the same thing. We know that 2 should shoot if P2[2] + P1[1] is bigger than 1, and if we look at it on the board--here we are--it's 2's turn, he's looking at this distance plus this distance, and is it bigger than 1? It is bigger than 1. So he should shoot. And we can go on doing this argument backwards., We'll find that Chevy should shoot here because this plus this is bigger than 1. And we'll know that here Patrick once again will know that Chevy's going to shoot tomorrow, so he should use Fact B, so he should shoot provided this plus this is bigger than 1, but it is. </p><p>Now, we're back at d* and the question we had at d*-- the question we'd left hanging at d*--was what? At d* we knew already that Chevy would not shoot if he thought Patrick was not going to shoot tomorrow, but he should shoot if thinks Patrick is going to shoot tomorrow, but what does Chevy know at d*?</p><p><b>Student:</b> I know Patrick is going to shoot.</p><p><b>Professor Ben Polak:</b> He knows Patrick's going to shoot, so he should shoot. Is that right? He knows Patrick's going to shoot by backward induction so he should shoot. So we just solved this. What did we actually show? We showed, have seats gentlemen--sorry to keep you up here--we know that prior to d* no one will shoot--will not shoot--and we know that at d*, and in fact at any point further on, we should shoot. That's horrible writing but it says shoot. So we've shown more than we claimed. We claimed that the first shot should occur at d*, and we've actually shown more than that: we've shown that even if you went beyond d*, and if somebody had forgotten to shoot at d*, at least you should shoot now. </p><p>Give me like two more minutes or three more minutes to finish this up because we're at a high point now. Everyone okay to wait a couple of minutes? Okay, so what did we prove here? We proved that the first shot occurs at d* whoever's turn it is at d*. It wasn't that the best guy, the better shot, should shoot first, or the worse shot should shoot first. It turned out that, given their abilities, there was a critical distance at which they should shoot. If you go back to the eighteenth century military strategy, you should shoot when you see the whites of their eyes, which is at d*. But we learned something else on the way. </p><p>I claimed we learned that if you're patient and you go through things carefully, that the arguments we've learned from the course so far, dominance arguments and backward induction arguments, can solve out a really quite hard problem. This was hard. It would have been useful for the guy in War and Peace, or in Onegin or the guys cycling in the Tour de France, or you guys with your sponges to know this. And we can solve this exactly using backward induction, and everyone in the room can do it. Let me just push the argument a tiny bit further. One thing we've always asked in this class, is okay that's fine if everyone knows what's going on in the game: here we have our smart Yale football players and they know how to play this game, so they're going to shoot at the right time. </p><p>But what happens if, instead of playing another smart Yale football player, they're playing some uneducated probably simple-minded football player from, say, Harvard. Now that changes things a bit doesn't it because we know that the Yale football player is sophisticated, has taken my class, and knows that he should shoot at d*, but the Harvard guy doesn't learn anything anymore, so they're stuck. So if you're the Yale guy playing the Harvard guy how does that change your decision? Should you shoot earlier than d* when you're playing against the Harvard guy, or later than d* when you're playing against the Harvard guy? Let's try our Yale guys and see what they think, what do you think Chevy?</p><p><b>Student:</b> Definitely not earlier.</p><p><b>Professor Ben Polak:</b> Definitely not earlier, that's the key thing right. Now why? Why definitely not earlier? </p><p><b>Student:</b> Because if you miss, the other person has a probability of 1, you have a higher chance of missing.</p><p><b>Professor Ben Polak:</b> All right, so I claim Chevy's right. That's good because I've just claimed that Yale football players are sophisticated. Chevy's right, that even if you're playing against a Harvard guy you shouldn't shoot before d* because it was a <i>dominant strategy</i> not to shoot before d*. It doesn't matter whether you think the Harvard guy is going to be dumb enough to shoot early or not. If he is dumb enough to shoot early, so much the better. You should wait until D*. Notice that argument doesn't depend on you playing against somebody who is sophisticated, or someone who's less sophisticated, like a Harvard football player, or somebody who's basically a chair, like a Harvard football player. You shouldn't shoot before d* because it's a dominant strategy not to shoot before d*. </p><p>Now, you might want to wait a little to see if they're not going to shoot early, to see if he's not going to shoot, but you certainly shouldn't shoot early. Let me finish with one other thing. Every time when we've played this game in class, whether it's here or up in SOM, people shoot too early. They miss. You can do the econometrics on this, you could figure out that, on average--average abilities--I'm sometimes getting the better shots, sometimes I'm getting the worse shots--on average I should see people hitting about half of the time over a large sample. But here I tend to see people miss, as we did today, almost all the time. Why do we see so many misses? </p><p>So one problem may be that people are just overconfident. They're overconfident on their ability to throw. And there's a large literature in Economics about how people tend to be overconfident. But there's another possible explanation, and let me just push it past you as the last thing for today. I think Americans--I think this doesn't go for the Brits--Americans have what I call a "pro-active bias." You guys are brought up since you're in kindergarten--maybe before--and you're told you have to be pro-active. You have "to make the world come to you." And my evidence for this is based on sophisticated empirical work watching Sports Center. So on Sports Center when they interview these sweaty athletes after the game, the sweaty athletes say, it's great I now control my own destiny. </p><p>Well, I'm a Brit. I think controlling my own destiny sounds kind of scary to me; it doesn't sound like a good thing at all. In fact, if I wanted to control my own destiny, I wouldn't have got married. That's going to be edited off the film, but the point I want to make is this. Every time I play this game, when I ask people why they shoot early I hear the same thing, and it's evidence to this proactive bias. People say, well at least I went down swinging and the problem is: the aim in life is not to go down swinging, it's not to go down. </p><p>So one lesson to get from this lecture is, sometimes waiting is a good strategy. Alright, and we'll come back to it on Monday.</p><p></p><p>[end of transcript]</p><p></h2>  </p></div><p><a id="backToTop" href="#top">back to top</p></a>