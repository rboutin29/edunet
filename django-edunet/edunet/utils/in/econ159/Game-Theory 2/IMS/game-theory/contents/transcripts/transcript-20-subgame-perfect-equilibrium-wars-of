<div id="fileContents"><h2><strong>Game Theory: </strong>Lecture 20 Transcript</h2><table cellspacing="0" cellpadding="0" id="transcriptHeader" summary="transcript header">	<tbody>		<tr>			<td id="transcriptDate">November 14, 2007</td>			<td id="transcriptNav"><span id="forwardNav"><a href="javascript:history.go(-1);">&lt;&lt; back</a></span></td>		</tr>	</tbody></table></p><p><b>Professor Ben Polak: </b>Last time we looked at how to apply our new idea of sub-game perfect equilibrium to a whole bunch of games, and our general idea for how to solve the sub-game perfect equilibrium is as follows. We looked at each sub-game. We solved for the Nash equilibrium in the sub-game, that is something we learned to do long ago. And then we rolled back the payoffs: we rolled them back up the tree. And towards the end we learned something interesting. I'm not going to go back to it today--I just want to emphasize it. We learned that strategic effects matter. </p><p>So in that investment game we looked at last time, when you're considering whether to rent a new piece of machinery, it made a very big difference whether you considered how this action would affect the actions of the other side; in this case, how it affects your competition. This is a very general idea, a very general point. So just to give you a couple of more examples, when you're designing tax systems--I mentioned this last time--when you're designing a tax system, to make some changes in the U.S. tax system, it's not good enough to look at how people are behaving in the old tax system and just calculate in an accounting manner how much more money you're going to raise, or how much money it's going to cost you. You have to take into account how that's going to lead to changes in behavior. </p><p>Once again, that's a strategic effect, and in the homework that you're handing in today, all of you will have had a nice example of that in the toll booth problem. So in the toll booth problem, when you're putting tolls on roads--or more generally, when you're building new roads, new bridges, new flyovers, new bypasses, you need to take into account how those new tolls, how those new roads will affect all of traffic flow. Traffic flow down the tree will form a new equilibrium and you need to consider that in designing your tolls and designing your road system. So that's another example of SPE. </p><p>So today I want to do something quite different, a little bit like what we did with duel, I want to play a game today, and probably spend the whole of today analyzing this one game. So it's quite a complicated game, but it's quite a fun game. So what's the game we're going to look at? The game is going to involve two players, and each player in each period, they choose--or each chooses I should say--each chooses, whether to fight or to quit. So F means fight and Q means quit, and they make this choice simultaneously. The game ends as soon as someone quits. </p><p>So there's good news and bad news for this game. Let's do the good news first. The good news is that if the other player quits first you win a prize. Generally we'll call this prize V, but we'll play for some cash in a minute. The bad news is, each period in which both fight--so each period in which both players choose to fight--each player pays a cost, so they pay -C. Just to keep things interesting let's fill in the other thing here which is if both quit at once--so if both quit at once then they get 0 that period. So this is a game we've seen a little bit before. We saw a little bit under the auspices of Hawk Dove. Those people in the MBA class saw a game a lot like this. But we're going to analyze this in much more detail then we did before. </p><p>As I said, we're going to spend the whole of today talking about it. So, to start this out, let's actually play this game. So I want two volunteers. Let me just, since this is college football season, let me see if I can play off the rivalries. So do I have anybody here from the great state of Texas? A whole bunch of Texans, keep your hands up. I want to use you a second and I guess the rivalry here is Oklahoma.: Anybody from Oklahoma? No Oklahomans? What we'll do is we'll pick two Texans then. We'll assume this is Texas and Texas A&amp;M. So Texans raise their hands again. All right, we're going to pick out two Texans and I'm going to give you a mike each. So your name is?</p><p><b>Student:</b> Nick.</p><p><b>Professor Ben Polak: </b>Why don't you keep hold of the mike and just point it towards you when you speak, but still shout because everyone here wants to hear you. So this is Nick, where was my other Texan back here? Why don't I go for the closer one. We'll start here. And your name is?</p><p><b>Student:</b> Alec.</p><p><b>Professor Ben Polak: </b>Alec, so shout it out.</p><p><b>Student:</b> Alec.</p><p><b>Professor Ben Polak: </b>That's better, okay. So the game is this. They're going to have to write down for the first period whether they choose fight or quit. Each player will have a referee. So the person behind Alec is going to be Alec's referee to make sure that Alec is actually saying what he says he's going to do. And what happened to my other Texan. I've lost my other Texan. There he is. Your name again was?</p><p><b>Student:</b> Nick.</p><p><b>Professor Ben Polak: </b>Nick is going to write down fight or quit. And to make this real, let's play for some real cash. So we'll make the prize--why don't we make the prize equal to a $1 and the cost equal to $.75. So I've got some dollars here. Here we go. What do we call this? In Texas we call this a fist full of dollars, is that right? So where are my players? Why don't you stand up, you guys. So everyone can see you. I made this difficult, because now you are going to have to write down your strategy. So you are going to have to grab a pen. I didn't make that easy for you. Let me come down to make it easier for the camera person. So why don't you write down what your strategy is going to be, and tell your neighbor what it's going to be, and we'll see what happened. Show your referee. Have you shown your referee? Nick, speaking into the microphone what did you do?</p><p><b>Student:</b> I quit.</p><p><b>Professor Ben Polak: </b>He quit.</p><p><b>Student:</b> I quit as well.</p><p><b>Professor Ben Polak: </b>What happened to remember the Alamo? All right, so Texas didn't work very well. Let's try a different state. I have to say my wife's from Texas and my wife's family is from Texas, and I thought they had more fight in them than that. Maybe that's why they are sliding in the polls. Let's try somebody from Ohio, anyone from Ohio? Nobody from Ohio in the whole class, that's no good. I was going to pick Ohio against Michigan. How about some people from some of our own teams? Are there any players on the football team other than the two I've picked on before? There we go. I need a different team, anybody from the hockey team? Anybody from the baseball team? Okay good. So our friend from the baseball team, your name is?</p><p><b>Student:</b> Chris.</p><p><b>Professor Ben Polak: </b>Chris and our new football team player is?</p><p><b>Student:</b> Ryland.</p><p><b>Professor Ben Polak: </b>Ryland. Okay so Ryland and Chris are going to play this. And neither of you is from Texas, I take it, so we have some hope of something happening here. So write down what it is you're going to choose. Have you both written something down? Yeah, all right Ryland what did you choose?</p><p><b>Student:</b> Fight.</p><p><b>Professor Ben Polak: </b>Chris?</p><p><b>Student:</b> I'm going to quit.</p><p><b>Professor Ben Polak: </b>Well that was easy too. So the football team is looking pretty good here. So we're not getting much in the way of action going here. Anyone else want to try here? Another little state rivalry here, I don't suppose I've got anyone from Oregon, that's asking too much, anyone from Oregon? You guys must be from somewhere. There's got to be a state where at least one of you is from. Well let's try something like New Jersey, how about that? There's some players from New Jersey that's good. Here we go. And we'll try New Jersey and New York. That seems like there's a bit of a rivalry there. Are you from New York? Excellent, here we go, and your name is?</p><p><b>Student:</b> Geersen.</p><p><b>Professor Ben Polak: </b>Your name is?</p><p><b>Student:</b> Andy.</p><p><b>Professor Ben Polak: </b>Andy. Okay so Geersen and Andy. So stand up so everyone can see where you are. Let's see if there's any fight in New York and New Jersey. So write down your strategies. Andy what did you choose?</p><p><b>Student:</b> I'm going to fight.</p><p><b>Student:</b> Fight.</p><p><b>Professor Ben Polak: </b>Here we go, this is better now. I was getting worried there for a second. I know it's near the Thanksgiving break, but there has to be some sort of spark left in the class. So we have both people fighting which means right now they're down $.75 but the prize is $1. So the game goes on, so write down again. What you're going to do second period. The $.75 is gone so now we're just looking at this game for $1. Let's go to New York, what does New York?</p><p><b>Student:</b> I'm going to fight.</p><p><b>Student:</b> Fight.</p><p><b>Professor Ben Polak: </b>Fight okay. So you have to stay on the east coast to get life. There's no point going west is there. That makes sense. So write down again what you're going to do, and let's go the other way around, to New Jersey?</p><p><b>Student:</b> Fight.</p><p><b>Student:</b> Fight.</p><p><b>Professor Ben Polak: </b>Fight again all right, so right now we're down three $.75 whatever that is, and there's still this prize of $1, plus perhaps a bit of pride here. So write down again. Let's try again, so let's go with New York this time.</p><p><b>Student:</b> I'm going to fight.</p><p><b>Student:</b> Fight.</p><p><b>Professor Ben Polak: </b>Fight okay, I'm guessing we could keep this going for quite a while, is that right? Now it might make a difference, by the way, if they're allowed to talk to each other here, so let's see if it does. So let's allow New Jersey and New York to talk to each other. You can't insult each other about bridges and tunnels, just regular talk. So anything you want to say to your friend from New Jersey here?</p><p><b>Student:</b> I can't let New Jersey win, that's just New York pride. You guys are just worse in every realm so I'm sorry. It's just pride.</p><p><b>Professor Ben Polak: </b>Anything you want to say in reply?</p><p><b>Student:</b> Well I'm going to keep fighting, so your best choice is to give up.</p><p><b>Professor Ben Polak: </b>Let's see if that works. Did they get anything out of that? So choose the strategies again. New York?</p><p><b>Student:</b> I just can't let Jersey win: fight.</p><p><b>Student:</b> Bring it on: fight.</p><p><b>Professor Ben Polak: </b>All right, so it's clear that if we kept this going for a while, it would pay for my lunch, is that right? We'll hold it here for a second. We'll talk about it a bit, but thank you. A round of applause for our two feistier players. So what's going on here? So clearly we can see what can happen in this game. You can get people quitting early, and it could be that one side quits and the other side doesn't quit. That is also something that can happen. That can happen pretty quickly. But it's possible--we just saw it happen--it's possible that a fight could go on quite a while here. </p><p>Now why? What's going on here? I mean the prize here was what? Was $1, and the cost was $.75. I could have raised the stakes maybe on these guys and see if that made a difference, but I think $1 and $.75 will do. And by the time they had fought the second time, they'd exhausted the possible prize of $1. So it's true that if you won this in the first period then that's fine because you just get a $1 and it wouldn't cost you anything. And even if you won in the second period you'd be okay, you'd only cost yourself $.75 for fighting in the first period, but you're getting $1 so that's good. But there on--and "there on" went on for plenty of time in this case--there on you're just accumulating losses, so what's going on? </p><p>There are various conclusions possible here. One is that people from New York and New Jersey are crazy. That's a possible thing. But what else is going on. Why did we get involved in this fight. What happened here? Why do we tend to see fights like this emerging? I'm claiming this isn't such an implausible situation. Why do we see it emerging? Let's talk to our friend from New York, shout out.</p><p><b>Student:</b> By the time she fought with me on the second round, I knew I was going to be losing money anyway so why not just keep going and then, there was no reason, I wasn't going to win anyway, so I might as well just keep fighting until she quit.</p><p><b>Professor Ben Polak: </b>All right, I think there's two things. There's two parts to that answer. Part of the answer is: I have lost the money anyway, let's hold that piece of it. And the other part of it is what? The other part of it is I'm really determined to win this thing. So there's two things going on there, and they're quite different. Let's take the second one first. It's possible that the reason these fights emerge and can go on for quite a while is that even though the prize is only $1 in money, it could be that the actual thing that the players care about is what? What do the players actually care about here? Somebody just raise your hand, I'll put you on the mike. What do people tend to care about in these situations? Winning, they care about winning, or they care about pride. Is that right? That's why I started with Texas, but I couldn't find any pride in Texas, so we had to go to New York. </p>
<p>So people care about winning per se. It's a pride thing. So it could be that $1 simply isn't a good description of the true payoffs here. It could be that the payoffs are actually about winning. It could also be that both of these guys know that they're going to be interacting with you at other times in the class, or other times at Yale. And they want to establish a reputation, both of them, as being the kind of guys who fight. In particular, when they got to talk about it, both of them said: "look I'm a fighter": something which we've seen before with Ale and his pizza shop. Both of them said: "I'm a fighter. You better back out." </p><p>So both of them tried to signal the fact that they were going to fight to try and get the other side to quit. So that's about reputation, and that reputation could extend beyond this game. It could be that they're going to be involved in this kind of conflict later on in life. So both of those things are around. There's another element to this, and it's the other part of what our friend from New York said which is about the costs. What's true about the costs in this game as we move from period to period? Somebody said it. Say it again. Say it loudly.</p><p><b>Student:</b> Sunk cost.</p><p><b>Professor Ben Polak: </b>It's a sunk cost. So all of those costs that you accumulate as the game goes on, they're irrelevant looking forward because they're sunk. The fact I've played this game for ten periods and hence lost ten times $.75--which even I can do, that's $7.50--the fact that I've lost $7.50 is irrelevant because I've lost it anyway. I can't get that back. That's a sunk cost. So the game ten periods through looks exactly the same as the game did at the beginning, when fighting seemed a good option. So ten periods through the game, you have the same view about fighting as you did at the beginning. </p><p>Now that's not quite true because at some point you're going to run out of money, but if we ignore that, basically, those sunk costs are irrelevant. So what we're seeing here is reasons why people fight and some of these reasons seem to be for standard economic reasons like sunk costs, and some of them seem to be about things that are outside the game like pride or possibly reputation. </p><p>It's certainly the case within the real world, we do see fights like this. Let's just spell out what the key feature of this is. The key feature of this is, in these fights over a period of time, even though you may only be losing a little piece in each period, over a period of time you could lose a lot. In fact, you could lose far more than the prize that was originally at stake. So the losses you could accumulate--and our friend from New Jersey and New York, the losses that they accumulated vastly outweighed the prize that was at stake after a while. That's a worry. </p><p>So this can occur in real life not just in the classroom. What do we call these kinds of fights; these fights where they're holding out for this possibly small prize and incurring, possibly small--but they accumulated to being large--costs each period. What do we call those fights? Let's think about some examples. Let's see if the word comes out of examples. </p><p>So one example--let's do some examples here. One example is what happened in World War I. So in World War I, as I'm assuming most of you know, on the western front at least, the German and allies to Germany armies faced off with the British and French and allied armies, for an extraordinarily long time, fighting over extraordinarily small patches of land, little pieces of northern France and Belgium. You could argue that these pieces of northern France and Belgium--I don't wish to offend anyone French or Belgian here--but you could argue that those few acres of northern France and Germany weren't worth a whole lot anyway. Nevertheless, the two sides kept on fighting from 1914 to 1918, and enormous losses of life were accumulated in that period. So that was a really costly, long term battle. Neither side would quit. Each year huge numbers of lives were lost. If you doubt that go and look at the war memorial in Yale that shows how many Yale American lives were lost, and America was only in that war for about a year. Okay, so that's an example. </p><p>Another example--a more business example, an example we talked about in our MBA class but not in this class so far--is examples in business where there's a market and that market is really only going to hold one firm. That market is only going to hold one firm. You can end up in an extremely long fight about who's going to end up being the one firm in that market. </p><p>So a famous example--actually it's a famous business school case--is the fight that ocurred to control satellite broadcasting in Europe. So there was a fight between Sky Television and the British Satellite Broadcasting Company that went on for a number of years. And these companies were doing things like charging zero prices, and giving away satellite dishes, and this that and the other. And over the course of the fight they accumulated so many losses that, if you did the accounting, the entire future projected profit flow of winning this fight was vastly outweighed by the amount of money that they'd lost during the fight. That was a fight that involved on one side Rupert Murdock and you can argue maybe Rupert Murdock is a little crazy and had a reputation to keep up, but still it looks like another example of this. So that example was British Satellite Broadcasting versus Sky. </p><p>So with those two examples there, anyone think of a general term we call these fights? How do people refer to the method of fighting in World War I--or for that matter during the American Civil War? Somebody in the back, shout it out.</p><p><b>Student:</b> War of attrition.</p><p><b>Professor Ben Polak: </b>It's a war of attrition. So these are wars of attrition. These are wars of attrition. And what we know about wars of attrition is that they can go on a long time, and a lot can be lost. A lot of life can be lost in the case of real wars. A lot of money can be lost in the case of business wars. Actually it turns out, a lot of games have this structure of a war of attrition. Let me give you one more example. Suppose that two companies are competing for a market not in the manner of BSB and Sky by the advertising or whatever, but in the form of paying bribes. </p><p>So suppose there's a company let's say in France and a company let's say in Britain, and these two companies are trying to win a contract in some country where paying bribes is a successful strategy. And here I'm going to be careful about the film and not mention any real companies, so let's call this imaginary country Freedonia, which comes from a Marx Brothers film. So here's this French company and this British company, and they both want this contract to build a bridge in Freedonia. And they start paying bribes to the general who controls Freedonia. And what happens? Well you're not going to get the bribe back. So both sides pay a few thousand dollars to this general, and then the general comes back and says, well you both paid $1,000. Which of you wants to pay the bridge? </p><p>So they go on, and they put more money in and more money in. And you can see once again this is a war of attrition. Those bribes that they've paid, they're never getting back, but once you've paid them they're a sunk cost. Once you've paid that bribe, good luck saying: I paid you this bribe. You didn't let me build the bridge. Give me my money back. There isn't a court in the world that's going to enforce that. So these bribery contests look a lot like this. There's a technical name for these bribe contests, they're sometimes called all pay auctions. So what do we want to establish today? </p><p>We want to establish-- we want to talk about why fighting occurs here and we wanted to do so in some detail. So there may be informal reasons why fighting occurs and we've talked about that. It could be that one side is crazy. It could be that both sides are crazy. It could be that national or regional pride is at stack. All of these things could affect why we get fighting. But what I want to try and establish today is that you can get long fights emerging in potential wars of attrition even if everybody is rational, even if the payoff is just that one dollar, and even if there's no reputation at stake. </p><p>So again, my goal today is to try and convince you that you can get huge loss of life in World War I or huge loss of money in these business contexts without having to argue something outside the model like irrationality or reputation. Even rational players can get themselves in trouble in wars of attrition. So for the rest of today, I want to try and analyze this. To get us started I want to look at a version of this game, at a simplified version, which only lasts for two periods. So we'll do a two period version of the game we played just now. Eventually, by the end of today, I want to look at the infinite version. So we'll start small. We'll start with a two period version. The trick in analyzing these things is to be able to come up with a tree and to be able to come up with payoffs, and be able to apply the analysis that we know about to get us to where we want to be. </p><p>So here's the game I claim. I claim that it has the following tree. So first of all Player A chooses and Player&nbsp;A can either Fight or Quit. And let me put a [1], and we'll see what the [1] is in a second. Then we're going to model Player 2. But of course this is a simultaneous move game. This is a simultaneous move, so this is an information set. Let's not call him Player 2. Let's call him Player B. So Player B doesn't know what A has done that first period when B is making her choice. This is a simultaneous move. And B is choosing between fighting or quitting. Just to distinguish them, let me use small letters for B, so once again fight or quit, and fight or quit. </p><p>Now, if both sides fight then the game continues. And everyone knows that both sides fought at that stage. So at this point on, we're actually at a singleton information node and it's Player A's turn again. So here we go again. So in the second period, once again, we've got A choosing whether to Fight or Quit. And this time we'll put a [2] to indicate we're in the second period. And after Player 2 has moved once again--after Player A has moved--once again Player B is moving. That's a simultaneous move. And once again they're choosing fight or quit. I'll put [2] to indicate that we're in the second stage. So that's the structure of this two period game. And let's write down what the payoffs are, starting with the easy payoffs. </p><p>So if both people quit in the first stage, they get nothing. If A quits and B fights, then A gets nothing and B gets V. If A fights and B quits, then A gets V and B gets nothing. And if they both fight we go into the second stage. So let's write down the payoffs in the second stage. So in the second stage, if they both quit in the second stage then their payoffs are going to be, for A, -C, the costs they accumulated in the first stage, plus 0. And, for B, -C + 0. If A quits and B fights in the second stage then the payoffs are -C + 0 and -C + V. If A fights and B quits then the payoffs are -C + V and -C + 0. And if they both fight for two periods, we have a decision to make about how we're going to end the game in this two period game, but let's just assume that what we'll get here is -C -C and -C -C. We'll assume if they both fight the game ends and no one gets the prize, just to make life simple. </p><p>So this is a two period version of the game and the only change I've made, other than making it two periods, is I had to put in a payoff. I had to see what happened if the game didn't resolve. And I've assumed that if the game didn't resolve, no one got the prize. </p><p>Now there's another assumption I'm going to have to make before we analyze this, there are two possible cases to consider here. There's the case when V &gt; C which is the case we just played in the class; and there's also the converse case when C &gt; V. So today we'll focus on the case V &gt; C which is the case we just played in class. I'm going to leave you to analyze the other case, the case when the cost is bigger than the prize, as a homework assignment. So V &gt; C is our assumption. So everyone okay with the tree? This tree I hope describes the game, at least a two period version of the game. </p><p>Now the first thing I want to point out here is, if we look at the payoffs that are incurred at the end of the second period game, we notice that they all contain a &ndash;C. There's a -C everywhere. What is that -C? It's the cost that you accumulated from having fought in the first stage. But the observation I want to make straight away is that this cost--so here it is, here it is, here it is, here it is, here it is, here it is, and here it is, and here it is--this cost is sunk. These objects here are sunk costs. There's nothing you can do once you're in the second period of the game to get these sunk costs back. They're just gone. They're there, but the fact that they enter everywhere is going to make them strategically irrelevant. Okay, so what we want to do here is we want to find all of the sub-game perfect equilibria of this little game. Let me get rid of the rules. We all know the rules by now. So our goal here is to use our solution concept, which is sub-game perfect equilibrium, to try and analyze this game. So how are we going to analyze this game in terms of sub-game perfect equilibria? How are we going to start that discussion? We've got a lot of work to do here, where are we going to start in finding sub-game perfect equilibria? What's the first thing we should do? </p><p>Well, I claim the first thing we should do is just figure out what the sub-games are. Let's start with that. So having just pushed it far away I'm going to need to use the pointer. I claim that the obvious sub-game to analyze first is this sub-game. It's the sub-game if you should end up in period [2]. And notice that it is a sub-game: it starts from a singleton node; it doesn't break up any information set; and it contains all of the descendants of the node from which it starts. So that is genuinely a sub-game. So we're going to start our analysis by considering the second sub-game. </p><p>So let's write down the matrix that corresponds to that second sub-game. And I'm going to write it down in the following way. So I claim, in this second sub-game, each player has two choices, they can fight or quit. And I'm going to write the payoffs in a particular way. I'm going to write the payoffs as -C plus this thing. So rather than keep that -C in all the boxes, which it's going to get boring after a while, I'm going to pull that -C out and just put it in front. Is that okay? So we had this sunk cost box everywhere and I'm going to pull out this sunk cost box and put it in front. So here it is. If you get into the second period of the game you've incurred this sunk cost. </p><p>And your payoffs in this game, if you both fight then you incur -C for the second time. If A fights and B quits, then A is going to win the prize so they'll get V and Player B will get nothing. If B fights and A quits, then conversely, A gets nothing and Player B gets the prize. And if they both quit they just get nothing. So just notice what I did here, I could have written out the box with -C-C here; -C-C here; -C+V here; -C+0 here; -C+0 here, etc.. But I just pulled out that -C because it's just distracting everything. So I pulled out that -C and put it in the front. Okay, so now we can analyze this little game, and let's start off by talking about pure strategy equilibria in this game. </p><p>So again, our goal is to find sub-game perfect equilibria, so the way in which we find sub-game perfect equilibria is what? We start at the last sub-games, we look for Nash equilibria in those last sub-games, and then eventually we're going to roll those back. So there's our last sub-game. There's the matrix for it. Let's just find the Nash equilibria. So if Player B is fighting then Player A's best response is to quit and if Player A is fighting then Player B's best response is to quit. Conversely, if Player B is quitting, Player A's best response is to fight, and if B is fighting--sorry: if A is quitting then Player B's best response is to fight. I didn't say that right. Let me try again. So if A is fighting, if the other side is fighting you want to quit. If the other side is quitting you want to fight. Is that clear? </p><p>So there are actually two--let's be careful here--pure strategy equilibria, there are two pure strategy Nash equilibria in this sub-game. What are they? They are (Fight,quit) and (Quit, fight). So if we get into the second sub-game and if we know we're going to play a pure strategy in the second sub-game, this is what's going to happen, that's our claim. Now notice that it didn't matter, the sunk cost didn't matter there. I could have included the sunk cost in the payoffs, but I would have found exactly the same thing with or without the sunk costs. So, as we'd expect, the sunk cost is irrelevant. So we've got both the equilibria in the sub-game. Let's roll these back into the first stage of the game. The payoffs associated with this one are V and 0, and the payoff associated with this one is 0 and V. Everyone okay with that? </p><p>Okay, let's revisit the first stage of this game. Now, things get a little bit more complicated, so what I'm going to do is I'm going to redraw the first stage of this game. So here it is. A can fight or quit just as before. And, following this, B can fight or quit just as before. So this is a picture of the first stage of the game, but I'm going to chop off the second stage. Let's put the payoffs in. So the payoffs down here are the same as they were before: (0, 0); working up, (0, V); if A fights and B quits then its V,0. But what about the payoff if they both fight? So what I want to do now is I want to look at the payoff when they both fight by considering what they would get, if they both fight, in the second period of the game. </p><p>So our idea is find the Nash equilibrium in the second period of the game and roll back these possible payoffs. So here the payoffs are going to be -C plus stage [2] Nash equilibrium payoffs for Player A; and -C plus the same thing, stage [2] Nash equilibrium payoffs for Player B. So just to understand what I've written here then, I put the same payoffs as before but I've replaced that enormous thing that was the second stage of the game, just with the payoffs that we know that we're going to get in the second stage of the game, if we play Nash equilibrium in the second stage. So these objects have a name, and the name is <i>continuation payoffs</i>. </p><p>These objects are the continuation payoffs. They are the payoffs I'm going to get tomorrow--and possibly forward in a more complicated case--if, in this case, if we both fight in the first period. Now what we want to do is we want to draw up the matrix that corresponds to this first stage game, and we're going to have to do so twice. We're going to have to do so once for the case where the continuation payoffs are (V, 0), where the equilibrium we're playing tomorrow is (Fight, quit). And we're going to have to do again for the case where the continuation payoffs tomorrow are (0, V), namely the continuation play is (Quit, fight). So we have to do it twice. </p><p>[So, you've got the continuation payoffs down so let's delete this to give ourselves a little room.]</p><p>So the matrix is going to look as follows: a nice big matrix, 2x2. Player A is choosing Fight or Quit, and Player B is choosing fight or quit. That much is easy. It's what we put in here that matters. So let's do all the easy cases first. So (Quit, quit) is (0, 0)' (Quit, fight) is (0,V); (Fight, quit) is (V, 0); and in here it's going to depend which of these two games--which of these two equilibria is being played tomorrow. So what we're going to do here is we're going to do the case for the equilibrium (Fight, quit) in stage two. We're going to write out the matrix for the case where we're going to play (Fight, quit) tomorrow. </p><p>[-Thank you, try and keep me consistent today, because it is very easy to slip up. So once again I'm going to use capital letters for Player A and small letters for Player B. ] </p><p>So what happens if we both fight? We both incur costs of C from fighting, and tomorrow we're going to get the payoffs from the equilibrium (Fight, quit). That's this equilibrium, so we're going to get V and 0 tomorrow. So let's add those in. So this will be +V and this will be +0. And let's just put some chalk around here to indicate that these are going to be continuation payoffs. So this is the matrix we're going to use to analyze the first stage of the game in the case where the equilibrium we're playing tomorrow is (Fight, quit). </p><p>And as I promised, we have to do this twice. So the other case, of course, is if we're in the other equilibrium tomorrow. So let's just do that. So once again we have Fight [1], Quit [1]; fight [1], quit [1];and the payoffs are--same as we had--(0,V); (0, 0); (V, 0); and then here, this time, we're going to have -C + 0 and -C + V. And the reason for the change is that we're now looking at the continuation game, the continuation play where it's Player A who quits in the second stage. So this is for the case (Quit [2], fight [2]) in period 2. </p><p>So let's just pause, let's make sure everyone's got that down, everyone okay? So what we've done here is we started off by analyzing what's going to happen in period 2, and that really wasn't very hard, is that right? That was a pretty simple game to analyze, pretty easy to find the equilibria. Then what we did was we rolled back the equilibrium payoffs from period 2 and we plunked them on top of the relevant payoffs in period 1. So in particular, if you both fight and you know you're going to play the (Fight, quit) equilibrium tomorrow, then you're payoffs will be -C + V and -C + 0. If you both fight and you know you're going to play the (Quit, fight) equilibrium tomorrow then you're payoffs will be -C + 0 and -C + V. </p><p>And just to emphasize once again, these four boxes we created correspond to the stage 2 Nash equilibrium payoffs, so the continuation payoffs of the game. Okay, so now we're ready to analyze each of these games. So this isn't going to be too hard. Let's try and find out the Nash equilibrium of this game. So let's start with the left hand one. This is the case where Player A is going to fight and win in period 2. So if Player B is going to quit in period 1 then, if Player A fights, she gets V; if she quits, she gets 0: so she's going to want to fight. Everyone okay with that? If Player B fights in period 2 [error; 1] then, if Player A fights, she gets -C + V and if she quits she gets 0, and here's where our assumption is going to help us. We've assumed, what did we assume? We assumed V is bigger than C, just like we played in class. So because V is bigger than C this is going to be the best response: again fighting is going to be the best response. </p><p>So we know that, in fact, Player A here has a dominant strategy, the dominant strategy is to fight in period 1 in this analysis of the game. And since A is fighting, not surprisingly, we're going to find that B is going to quit. So B's best response is to quit. So here is our Nash equilibrium in this sub-game. This game has a Nash equilibrium, it only has one, and the equilibrium is (Fight [1], quit [1]).</p><p>Now let's just talk about it intuitively for a second. Intuitively, if I know, if I'm playing Jake, and I know that Jake is going to fight tomorrow--sorry, other way round--I know that Jake's going to quit tomorrow and I'm going to fight tomorrow--I know that tomorrow I'm going to win. So that prize is there for me tomorrow, so why would I want to quit today? I'm going to get $1 tomorrow if I just fight in this period. So why would I want to quit today when, at worst case scenario, I'm only going to lose $.75 today. So if I know Jake is quitting tomorrow I'm going to stay on and fight now. And conversely, if Jake knows he's quitting tomorrow, hence, he knows I'm going to fight now, he may as well just quit. So what we're learning here is in this particular example, if we know that tomorrow I'm going to win the war, I'm actually going to win it today. Say it again, if we know that tomorrow I'm going to win the war, I'm actually going to win it today. </p><p>The converse is true for the case where I'm the quitter and Jake's the fighter tomorrow. So once again it's pretty quick to see that from Jake's point of view if I'm going to fight he's going to want to fight. If I'm going to quit, he's going to want to fight. So in either case he's going to want to fight. So I'm going to want to quit. So the Nash equilibrium in this game is (Quit [1], fight [1]). </p><p>So at this stage, we found all of the pure strategy sub-game perfect equilibria in the game. Let's describe them before I write them up. One pure strategy Nash equilibrium has me fighting in period 1 and Jake quitting in period 1; and if we got to period 2--which in fact we won't--then I fight again and he quits again. So let's write that equilibrium up and we'll do it here. We'll do it on the top board actually. So let me get it right, when I write it up as a whole equilibrium. So I claim that I've now found all of the pure strategy SPE in this game. One of them involves my fighting in the first period and fighting in the second period, and Jake quitting in the first period and quitting in the second period. The other one just flips it around, I quit in the first period, and if I got there I would quit in the second period and Jake fights in the first period and, if he got there, he would also fight in the second period. </p><p>So these are perfectly natural equilibria to think about. If you want to get it intuitively, each of these equilibria involves a fighter and a quitter. The fighter always fights, the quitter always quits. If I know that I'm playing a quitter, I'm always going to fight, so that's a best response. If I know I'm facing a fighter, I'm going to want to quit, so that's a best response and those are two very simple equilibria. That's the good news. What's the bad news here? The bad news is we haven't achieved our goal. Our goal was to argue that rational players might get involved in a fight, and notice that in each of these two pure strategy sub-game perfect equilibria, in each of them, no real fight occurs. Is that right? </p><p>In each of them one person fights for the first period, but the other person just runs away. That isn't much of a fight. Let me say it again. In each of these equilibria, one side is willing to fight, but the other side isn't, so no fight occurs. In particular, no costs are incurred in either of these equilibria. But I claimed at the beginning, I wanted to explain how we could have costs occur in equilibrium. Rational players are going to incur costs. So what am I missing here? What should I do to try and find a more costly equilibrium? I claim I'm still missing some equilibria here. What kind of equilibria am I missing? I'm missing the mixed strategy equilibria. </p><p>So far, all we've done is solve out the pure-strategy equilibria but we need to go back and re-analyze the whole game looking now for mixed strategy equilibria. So we're going to do the entire--take a deep breath, because we're going to take the whole analysis we just did, we're going to repeat the entire analysis we just did, but this time we're going to look at mixed strategy equilibria. Everyone happy with what we're doing? So first of all, we're going to go back to the second sub-game. Here's the second sub-game, and we already found the pure strategy equilibria, so let me get rid of them, and in your notes you probably want to rewrite this matrix. But I'm not going to rewrite it here because we're a little bit short of time. </p><p>This is exactly the same payoff matrix we saw before, but now I want to look for a mixed strategy equilibrium in this game. How do I go about finding--it's good review this--how do I go about finding a mixed strategy equilibrium in a game like this? What's the trick for finding mixed strategy equilibria? Should we try our guys from New Jersey and New York? Let's try our guys from New Jersey and New York. Where's my New Yorker? We'll have the true battle here between New York and New Jersey, how do we find a mixed strategy equilibrium?</p><p><b>Student:</b> You use the P's and Q's and set them equal to one another. That's a very crude explanation.</p><p><b>Professor Ben Polak: </b>That's a crude thing okay. So the answer was we find the P's and Q's and "set them equal to one another." What is it we're actually setting equal to what? Let's try and get some response on this. Did our New Jersey guy flee? Where's my New Jersey person? They fled. We could give our Texans another chance. Where's our Texan? Tthere was a Texan down here somewhere, what is it they set equal to what? </p><p><b>Student:</b> I guess the chances that one would quit and the other would fight.</p><p><b>Professor Ben Polak: </b> Not quite. The remark about using P's and Q's was right. This is good review for the final. What is it I'm going to do with those P's and Q's? Shout it out.</p><p><b>Student:</b> You use the other player's payoffs.</p><p><b>Professor Ben Polak: </b>Use the other player's payoffs and?</p><p><b>Student:</b> Make them indifferent between their strategies.</p><p><b>Professor Ben Polak: </b>Good. I'm going to choose Player B's mix in such a way as to make Player A indifferent between choosing fight and quit. So as to make it plausible that A is actually mixing. So again the intuition is for A to be mixing they must be indifferent between fight and quit. So I'm going to choose the mix of B to make A indifferent. So that's good review. Let's do that. So here I've usually used the letter Q but to avoid confusion here, let me use the letter P. We're going to choose P to make Player A indifferent. </p><p>So if A fights then their payoff is what? Let's have a look. It's -C with probability P, and V with probability of 1 - P. This should be coming back now. This is before the mid-term, but you guys were alive before the mid-term so you should remember this. So if they fight, they get -C P + V [1--P]. If they quit then they get 0 with probability P, and 0 again with probability 1 - P. So we know that if A is mixing, B must be mixing in such a way as to make these two numbers equal. So we know these two must be equal to one another. Since they're equal we can now solve for P, so what's that going to give us? It's going to give us V [1--P] = P . C and that I think is P = V / [V + C]. Is that right? Someone just check my algebra. </p><p>If you remember the game of Hawk Dove that we saw just before the mid-term--it was a game we looked at when we looked at evolution--this is essentially the same game more or less as that game, and that you'll notice it's the same kind of mixture we've got here. So P = V / [V + C] which means 1 - P = C / [V + C]. I'm leaving it up there for a bit hoping that one of the T.A.'s is just going to do my algebra for me. I think that's right though. So this game is symmetric so we could do the same for B but we'll find the same thing: it's a symmetric game. So the mixed strategy equilibrium, the mixed Nash equilibrium in this game has both mix, both fight with probability equal to V / [V + C]. Now this is good news, because at least we are getting some fighting going on, but we need to do something. </p><p>We need to take this Nash equilibrium we've just found, which is a Nash equilibrium in the second sub-game. It's a Nash equilibrium in the sub-game way up here. And we need to roll back the payoffs from this sub-game, the equilibrium payoffs from this sub-game into the first stage. That's our method. How are we going to do that? Well we better first of all figure out what those payoffs are. So what are the payoffs in this equilibrium? The payoffs in this mixed Nash equilibrium are what? Anyone see what the payoffs are going to be if they're both playing this mix? Well presumably the payoff from fight and the payoff from quit must be the same, is that right? So we may as well choose the easier one. </p><p>So I claim that the payoff from quit is 0 x P + 0 x 1 - P which is 0. V / [V + C] + 0 . C / [V + C] but that's equal to what? 0, okay good. So it's got to be the case (kind of conveniently) that if they do play this mixed strategy equilibrium in stage 2, the payoff they'll get from playing it is 0. That's going to make life a little bit easier later on. That's our new equilibrium in the second sub-game. Now let's roll that back to the first game. </p><p>Here's our first game again, and everything about this is correct except what's down here. So let's get rid of what's down here. Our analysis from before is more or less still intact. It's still the case, that if they both quit they'll get 0. If they (Quit, fight) they'll get (0, V); or (V, 0) and it's still the case if they both fight they'll both incur costs of C and they'll both then get stage 2 continuation Nash payoffs. Is that right? </p><p>But now instead of those continuation Nash payoffs being (V, 0) or (0, V), those continuation Nash payoffs are going to be what? They're going to be 0. So what we're going to do here is we're going to backward induct, or roll back, those zero payoffs and come up with the corresponding matrix to describe the first stage of the game. Here it is. Fight, Quit--I'll try to get it right without Jake having to correct me this time--little f, little q. This is A. This is B. And the payoffs here are (0, 0) here; (0, V); (V, 0) just as before; and, in this box now, we've got -C + 0 and -C + 0. So it's exactly the same box we saw before, but now the continuation payoffs are just 0. </p><p>Again, what is this? This is for the Nash equilibrium--let's just say for the mixed Nash equilibrium in period 2. Now what I want to do is I want to find the mixed equilibrium in period 1. We found the mixed equilibrium in period 2. Now I want to find the mixed equilibrium in period 1. So what I could do here is I could spend a lot of time. I could put in a P and a 1 - P and I could work out what mix of Player&nbsp;B will make A indifferent. I could work out what mix of Player A would make B indifferent. But has anybody noticed something about this matrix? What do you notice about this matrix? Somebody help me out? Somebody's got to help me out here. Tell me something about this matrix. What's true about this matrix?</p><p><b>Student:</b> It's the same as the one above.</p><p><b>Professor Ben Polak: </b>It's the same as the one above. The matrix I just drew, when I rolled back the payoffs is exactly the same matrix that I had here. It's exactly the same matrix. So we already know what the mixed strategy equilibrium is in this. The mixed Nash equilibrium in this matrix is both fight with probability P = V / [V + C] So now we're ready to show our new sub-game perfect equilibrium, let's drag it down. </p><p>Here's our whole game, we found the pure SPEs but now we're ready to find the mixed SPE. The mixed sub-game perfect equilibrium has Player A--before I do that let me just give this P a name. Let me call this P, P*. So V / [V + C], let's call it P*. So the mixed sub-game perfect equilibrium has Player I mixing, fighting with probability of P* in the first stage; and in the second stage, again mixing, fighting with probability of P*. So this is Player 1 and Player 2 does exactly the same thing. While we're here, what's the expected payoff for each player if they're playing this mixed sub-game perfect equilibrium? It's 0--the payoff from this--the expected payoff is 0. </p><p>So now we're actually getting somewhere, now we're really getting somewhere. So let's just take a deep breath and see where we are. We broke this game down, this complicated game we played in class, that conceivably--for example, when New York is playing New Jersey--conceivably it could go on all night. Apparently not when the Texans are playing each other or the football team is playing the baseball team, but when we have New York and New Jersey it could go on all night. We curtailed it to a two period game, but in a minute, we're going to go back to the infinite game. In this two period game, I tried to argue--I'm trying to convince you--that you could get fighting occurring just in equilibrium with absolutely standard rational players: nothing to do with pride, nothing to do with reputation, nothing to do with the fact that these guys are crazy guys who drunk the water in New York and New Jersey, God help them. </p><p>You can get fighting with ordinary people in equilibrium. What we've shown is the way in which you can get fighting is in a mixed strategy equilibrium. In each period of the game, people fight with probability P. That's just enough fight to give the other side an incentive to quit and just enough probability of the other side quitting to give the other side an incentive to fight; just exactly enough. If they play that equilibrium in every period, there's some chance of the game ending but with probability P, the game goes forward to the next period. So you could potentially have fights for two periods. </p><p>By the way, with what probability would there be a fight in both periods? That's a good homework question, I won't answer it here, you can work it out at home. Should we do it here? Anybody want to tell me? So okay, with what probability do we get a fight in the first period; a real fight, a fight involving both players? We need both players to fight, each are fighting with probability of P, so the probability of both of them fighting is what? P&#178;. So to get a fight in the first period, the probability is P&#178;. To get a fight in both periods is what then? P<sup>4</sup>. But we get a fight with probability of P<sup>4</sup> going through. We get fighting in equilibrium. Moreover, we get some very intuitive things that we already learned in the Hawk-Dove game. The probability of fight--so in this equilibrium--the probability of fights occurring goes up as V goes up. So the prize gets bigger, you're more likely to see fights occur: that seems right. It goes down in C. So the probability of fights occurring goes up in the size of the prize--that seems intuitively right--and down in the cost of fighting. </p><p>Now, okay, that's reasonable, but I claimed I could show you this not in a two period game, but in an infinite period game. So let me spend the last five minutes taking us to infinite period games. So everybody take a deep breath. We're now going to consider something, we've never done before. We're going to consider a game that could go on forever. It could go on forever. The way we're going to do that is to use the following idea, the following picture. So I can't really draw a true tree for the infinite period game. The reason I can't draw a true tree for the infinite period game is: (1) I would run out of chalk; and (2) I'd run into lunch time. But you can imagine what it looks like. It looks like this, roughly speaking. </p><p>The infinite period game looks something like this. And then it goes again, and then it goes again, and so on, and it would go right the way through the board and work right the way across whatever street that is, right across campus. That's what the infinite tree would look like, so I clearly can't really analyze that object. But what I want to show you is that we can still solve this game even though it's an infinite period game. How are we going to do that? Let's look at a particular stage. Let's call the stage Stage 4,503 whatever that number was: 4,503, whatever it was. So here is the stage, this arbitrary stage, and the tree for this arbitrary stage looks like this. </p><p>What I'm going to do is: this is Stage 4,503, and what I'm going to add to this is that before you get into this stage, you're going to incur sunk costs. If you go on playing after this stage then you're going to get continuation values. So going into the beginning of the game, you've incurred some sunk costs and if you come out on the other side and go on playing, you're going to play some equilibrium and get continuation values. But otherwise everything else is the same. We still have (0, 0) here, we still have (0, V) here, we still have (V, 0) here and here we still have -C plus continuation values and -C plus continuation values. This is something we've seen before. This little box is something we've seen before. </p><p>Essentially we've got sunk costs in front, but they're irrelevant. We've got continuation values at the end but we know how to handle them, we just put them into the payoffs. So suppose now that in the continuation game, people play the mixed strategy that we just found. Suppose that in the continuation game people mixed with probability P: so they fight with P* and quit with probability 1 - P*. Suppose in the continuation game they're playing a mixed strategy. In that case, what is the continuation value of the game? What is it? It's 0 right. </p><p>If they're mixing in the future, they always have the option to quit so it must be that the continuation value is 0. So if they mix in the future then the continuation value is (0, 0). So now let's go back to this board. To make this board equivalent to the board above, all I need to do is one thing. I need to add on some sunk costs at the front. I've got sunk costs at the front. I'm going to play the game. And then I'm going to get, instead of stage 2 values, I'm going to get stage--what was it?--4,503 and all stages in the future values in here and here, but otherwise it's the same thing. And what's convenient is: all of those are 0 anyway. Since they're all 0 anyway, this matrix is still correct, the continuation values are 0 and 0, these are now the continuation values. And so if I look for a mixed-strategy equilibrium in this game, it's something I've solved already. What's the mixed strategy equiliibrium in this game? Anybody? It's exactly what we found before. Just as before, I'm going to mix with probability of V / [V + C]. </p><p>Let's summarize, we did something today--just now--that we've never done before. We've looked at an infinite or at least potentially infinite period game: a game that could go on forever. The way in which we handled the game that could go on forever was what? We noticed two things. We noticed that part of the game that comes before, that part of the game that's passed already, anything that happened there is just a sunk cost. It's irrelevant. It hurts if it's a cost. It's nice if it's a gain. But it's sunk, you can't affect it now. Anything in the future can be summarized by the value, the payoff I'm going to get in the future by playing the equilibrium in the future. In this case, the future meant mixing. Mixing gave me the value of 0. So here I am getting 0 from the future. </p><p>Then I can just analyze the game in the stage in which I'm in, just as if it was an ordinary, bog-standard, simultaneous move game. When we did so, in this particular example--we're going to see more examples like this after the break--but in this particular example, we found out something quite surprising. This thing we found out was, in these war of attrition settings, there is an equilibrium with rational players--more than that, common knowledge of rationality: everybody's rational, everyone knows everyone else is rational--there are equilibria in which, not only people fight but they could fight forever. In every period they fight with some probability and we got an extra prediction out of it, a prediction that we weren't expecting. </p><p>Let me just give you that prediction, and then we'll leave the class with that. The extra prediction is this, if we look at these wars of attrition, and we keep track of the time in which the--hang on guys don't rush to the back yet--one more thing. If we look at the time in which the games have gone on and keep track of the probability that a war will end at that time. So imagine this is World War I. You could imagine World War I going for one year, or two years, or three years, or 20 years or whatever. The probability distribution in this war of attrition is going to look like this. In every period, the probability of continuing is just P*&#178;. So, in every period, the chance that--as you get further into the future there's a greater chance the war will end. You can get very long, very costly wars; that's the bad news. The good news is it doesn't happen very often. I guess we're all involved in a rather large and costly war right now, so I'll leave you with that pleasant thought over Thanksgiving. Have a good break and we'll see you afterwards.</p>
<p></p><p>[end of transcript] </p><p></h2></p></div><p><a id="backToTop" href="#top">back to top</a></p></body></html>

  </p>
</div>
